{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script extracts and combines neccessary features from various datasets into one dataset.\n",
    "\n",
    "\n",
    "Pseudo code\n",
    "-----------\n",
    "1. Generate filepath to verbal autopsy CSV data based on predefined patterns\n",
    "2. Extract the necessary features from each file\n",
    "3. Merge extracted features into a single dataframe using the \"rowid\" as the key\n",
    "4. If PROPORTIONAL_SAMPLING == True\n",
    "    4.1. Calculate the no. of records proportion of (age_group+round)/all_records\n",
    "    4.2. Sample each based on calculated proportion \n",
    "    4.3. Handle potential oversampling\n",
    "5. Generate unique id (uid) for each row\n",
    "6. Save completed dataframe to as JSON file for Step 02\n",
    "\n",
    "\n",
    "\n",
    "Details regarding #1 to #3 of the pseudo code:\n",
    "----------------------------------------------\n",
    "\n",
    "The HEALSL datset provides verbal autopsy (VA) data divided into different\n",
    "files. As of writing, there are two rounds of data, round 1 and 2, study\n",
    "conducted at different time periods. Each round is divided into three age\n",
    "groups: adult, child, and neonate. Each record is normalized into into three\n",
    "files: questionnaire, age, and open narrative, sharing the samw rowid as the\n",
    "key. The questionnaire provides the sex of the deceased, the age dataset\n",
    "provides the age of the deceased, and the narrative dataset provides the open\n",
    "narrative recorded from the VA data.\n",
    "\n",
    "The purpose of this script is to extract all the necessary features scattered in\n",
    "different files into one dataset.\n",
    "\n",
    "The pattern is based on the following\n",
    "\n",
    "    variables:\n",
    "    rounds (r):     rd1, rd2\n",
    "    age_groups (a): adult, child, neo\n",
    "\n",
    "    filename patterns:\n",
    "    questionnaire:  healsl_{r}_{a}_v1.csv\n",
    "    age data:       healsl_{r}_{a}_age_v1.csv\n",
    "    narrative data: healsl_{r}_{a}_narrative_v1.csv\n",
    "\n",
    "    This will result in 12 files for each round of data.\n",
    "    e.g.\n",
    "    healsl_rd1_neo_v1.csv\n",
    "    healsl_rd1_neo_age_v1.csv\n",
    "    healsl_rd1_neo_narrative_v1.csv\n",
    "    ...\n",
    "    healsl_rd2_adult_v1.csv\n",
    "    healsl_rd2_adult_age_v1.csv\n",
    "    healsl_rd2_adult_narrative_v1.csv\n",
    "\n",
    "\n",
    "Details regarding #4 of the pseudo code:\n",
    "----------------------------------------\n",
    "\n",
    "The script can alternatively generate a sample of the dataset based on the\n",
    "proportion of records. This can be used to repeatiedly request a response to the\n",
    "same question and compare the results among different repetitions. Since some\n",
    "age groups + round segments have limited number of records, we sample from each\n",
    "segment proportionally to ensure that each segment is represented in the sample.\n",
    "\n",
    "Due to rounding errors from the calculated proportion, oversampling may happen.\n",
    "This is handled by removing the extra rows from the group with the highest\n",
    "proportion to ensure groups with the lowest samples maintains \n",
    "their prescence.\n",
    "    \n",
    "    \n",
    "Details regarding #5 of the pseudo code:\n",
    "----------------------------------------\n",
    "\n",
    "The format of the unique id (uid) depends on whether PROPORTIONAL_SAMPLING is True or False. \n",
    "    \n",
    "    PROPORTIONAL_SAMPLING is False, the uid is similar to the rowid.\n",
    "    PROPORTIONAL_SAMPLING is True, rowids will no longer be unique as it is being repeated n \n",
    "    times. Hence, uid = f\"{rowid}_{n}\"\n",
    "\n",
    "\n",
    "Miscellaneous:\n",
    "--------------\n",
    "\n",
    "- age group and round number is appended to the dataset as a feature. These will help splitting \n",
    "  the results back into their respective groups, as needed.\n",
    "- some features, e.g. \"sex_cod\", were empty in the dataset, and treated as NaN by the script.\n",
    "  These were filled as empty string \"\" to avoid any issues during the experiment.\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "TIMEZONE = pytz.timezone('America/Toronto')\n",
    "\n",
    "\n",
    "# Set PROPORTIONAL_SAMPLING to True to sample the dataset proportionally, and False retain the entire dataset\n",
    "# N_REPEAT_RESPONSES and N_SAMPLES are only used when PROPORTIONAL_SAMPLING is True\n",
    "PROPORTION_SAMPLING = False\n",
    "N_REPEAT_RESPONSES = 10\n",
    "N_SAMPLES = 100  # Replace X with the desired number of values to select\n",
    "\n",
    "# Output filename after processing the dataset\n",
    "# appends datetime, and sampled if PROPORTIONAL_SAMPLING is True\n",
    "OUTPUT_FILE = \"healsl_dataset_all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyl\\AppData\\Local\\Temp\\ipykernel_50328\\3298851952.py:10: DtypeWarning: Columns (2,105,205,206,215,216,316) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n",
      "C:\\Users\\andyl\\AppData\\Local\\Temp\\ipykernel_50328\\3298851952.py:10: DtypeWarning: Columns (182,245) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: rd1        age group: adult      len: 4987      \n",
      "round: rd1        age group: child      len: 2998      \n",
      "round: rd1        age group: neo        len: 585       \n",
      "round: rd2        age group: adult      len: 2025      \n",
      "round: rd2        age group: child      len: 1059      \n",
      "round: rd2        age group: neo        len: 233       \n",
      "\n",
      "Total length of merged_all_df: 11887\n"
     ]
    }
   ],
   "source": [
    "path_prefix = \"../data_202402/\"\n",
    "merged_all_df = pd.DataFrame()\n",
    "\n",
    "rounds = ['rd1', 'rd2']\n",
    "age_groups = ['adult', 'child', 'neo']\n",
    "\n",
    "for r in rounds:\n",
    "    for a in age_groups:\n",
    "        \n",
    "        questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n",
    "        age_df =            pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_age_v1.csv\")\n",
    "        narrative_df =      pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_narrative_v1.csv\")\n",
    "\n",
    "        narrative_df = narrative_df.rename(columns={'summary': 'open_narrative'})\n",
    "        \n",
    "        # Merge the dataframes\n",
    "        narrative_only = narrative_df[['rowid','open_narrative']]\n",
    "        sex_only = questionnaire_df[['rowid','sex_cod']]\n",
    "        age_only = age_df[['rowid','age_value_death','age_unit_death']]\n",
    "        \n",
    "        merged_df = narrative_only.merge(sex_only, on='rowid').merge(age_only, on='rowid')\n",
    "\n",
    "        # Fill in missing values with empty string\n",
    "        merged_df['sex_cod'] = merged_df['sex_cod'].fillna('')\n",
    "        \n",
    "        merged_df['age_group'] = a\n",
    "        merged_df['round'] = r\n",
    "        \n",
    "        # merged_df['group'] = f\"{a}_{r}\"\n",
    "\n",
    "        assert not merged_df.isnull().values.any(), \"Execution halted: NaN values found in merged_df\"\n",
    "\n",
    "        print(f\"round: {r.ljust(10)} age group: {a.ljust(10)} len: {str(merged_df.shape[0]).ljust(10)}\")\n",
    "        # print(f\"Sample of merged_df {merged_df.shape}:\")\n",
    "        # display(merged_df.sample(5))\n",
    "        \n",
    "        merged_all_df = pd.concat([merged_all_df, merged_df])\n",
    "\n",
    "print(\"\")        \n",
    "print(f\"Total length of merged_all_df: {len(merged_all_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a sample of the merged_all_df\n",
    "if PROPORTION_SAMPLING:\n",
    "    \n",
    "    # age_group + round is essentially the group, this column will assist collecting samples from different groups\n",
    "    merged_all_df['group'] = merged_all_df['age_group'] + \"_\" + merged_all_df['round']\n",
    "\n",
    "    # Get the sampling fraction\n",
    "    sampling_frac = ((merged_all_df.value_counts('group') / len(merged_all_df)) * N_SAMPLES).round(0).astype(int).to_dict()\n",
    "    \n",
    "    # Initialize the dictionary to store the sample ids\n",
    "    sample_ids = {}\n",
    "\n",
    "    # Get sample based on fraction for each group\n",
    "    for sample in sampling_frac:\n",
    "        sample_ids[sample] = merged_all_df[merged_all_df['group'] == sample].sample(sampling_frac[sample], random_state=1).rowid.tolist()    \n",
    "        print(f\"{sample}: {sampling_frac[sample]} records\")\n",
    "        \n",
    "    # Sort dict from largest group to smallest\n",
    "    sorted_sample_ids = dict(sorted(sample_ids.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "\n",
    "    # Get the actual samples count\n",
    "    sample_values_count = len([item for subitem in sorted_sample_ids.values() for item in subitem])\n",
    "\n",
    "    # If sample count is more than N_SAMPLES required, remove the excess samples\n",
    "    # starting from the group with the most samples and more than 10 samples\n",
    "    if sample_values_count > N_SAMPLES: \n",
    "        excess = sample_values_count - N_SAMPLES\n",
    "        print(f\"There are more than {N_SAMPLES} samples. Removing excess samples.\")\n",
    "                \n",
    "        for _ in range(excess):\n",
    "            for key in sorted_sample_ids:\n",
    "                \n",
    "                if len(sorted_sample_ids[key]) > 10:\n",
    "                    sorted_sample_ids[key].pop()\n",
    "                    break\n",
    "    else:\n",
    "        print(f\"There are {sample_values_count} samples. No need to remove any samples.\")\n",
    "        \n",
    "    # Flatten the sample dictionary to a list of rowids\n",
    "    sample_ids_list = [item for sublist in sorted_sample_ids.values() for item in sublist]\n",
    "\n",
    "    # Compile a dataframe based on the sample rowids\n",
    "    random_rowids = merged_all_df[merged_all_df['rowid'].isin(sample_ids_list)]\n",
    "    \n",
    "    # Construct a unique id rowid_repetition and append to the dataframe\n",
    "    final_df = pd.concat([random_rowids.assign(uid=random_rowids['rowid'].astype(str) + \"_\" + str(r)) for r in range(N_REPEAT_RESPONSES)])\n",
    "    \n",
    "    # done with 'group', so drop it\n",
    "    final_df = final_df.drop(columns=['group'])\n",
    "\n",
    "    \n",
    "# Using full dataset\n",
    "else:\n",
    "    \n",
    "    # Duplicate rowid as uid \n",
    "    final_df = merged_all_df.assign(uid=merged_all_df['rowid'])\n",
    "\n",
    "# Reorder uid as first column for presentation\n",
    "final_df = final_df[['uid'] + [col for col in final_df.columns if col != 'uid']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>rowid</th>\n",
       "      <th>open_narrative</th>\n",
       "      <th>sex_cod</th>\n",
       "      <th>age_value_death</th>\n",
       "      <th>age_unit_death</th>\n",
       "      <th>age_group</th>\n",
       "      <th>round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14002421</td>\n",
       "      <td>14002421</td>\n",
       "      <td>according to the granddaughter of the deceased...</td>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "      <td>Years</td>\n",
       "      <td>adult</td>\n",
       "      <td>rd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14005966</td>\n",
       "      <td>14005966</td>\n",
       "      <td>According to respondent, the deceased was a 29...</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>Years</td>\n",
       "      <td>adult</td>\n",
       "      <td>rd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14001514</td>\n",
       "      <td>14001514</td>\n",
       "      <td>According to the deceased sisters, the decease...</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>Years</td>\n",
       "      <td>adult</td>\n",
       "      <td>rd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14009193</td>\n",
       "      <td>14009193</td>\n",
       "      <td>According to the niece the deceased was a male...</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Years</td>\n",
       "      <td>adult</td>\n",
       "      <td>rd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14002210</td>\n",
       "      <td>14002210</td>\n",
       "      <td>According to the younger sister who was with h...</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>Years</td>\n",
       "      <td>adult</td>\n",
       "      <td>rd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>24002039</td>\n",
       "      <td>24002039</td>\n",
       "      <td>As per respondent, the deceased was a 7 days  ...</td>\n",
       "      <td>Female</td>\n",
       "      <td>7</td>\n",
       "      <td>Days</td>\n",
       "      <td>neo</td>\n",
       "      <td>rd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>24002598</td>\n",
       "      <td>24002598</td>\n",
       "      <td>The deceased was a 0 old day female neonate wh...</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Days</td>\n",
       "      <td>neo</td>\n",
       "      <td>rd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>24001849</td>\n",
       "      <td>24001849</td>\n",
       "      <td>According to the mother of the deceased, she h...</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Days</td>\n",
       "      <td>neo</td>\n",
       "      <td>rd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>24000702</td>\n",
       "      <td>24000702</td>\n",
       "      <td>According to the respondent, the deceased was ...</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Days</td>\n",
       "      <td>neo</td>\n",
       "      <td>rd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>24001069</td>\n",
       "      <td>24001069</td>\n",
       "      <td>According to the respondent, the deceased was ...</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Days</td>\n",
       "      <td>neo</td>\n",
       "      <td>rd2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11887 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid     rowid                                     open_narrative  \\\n",
       "0    14002421  14002421  according to the granddaughter of the deceased...   \n",
       "1    14005966  14005966  According to respondent, the deceased was a 29...   \n",
       "2    14001514  14001514  According to the deceased sisters, the decease...   \n",
       "3    14009193  14009193  According to the niece the deceased was a male...   \n",
       "4    14002210  14002210  According to the younger sister who was with h...   \n",
       "..        ...       ...                                                ...   \n",
       "228  24002039  24002039  As per respondent, the deceased was a 7 days  ...   \n",
       "229  24002598  24002598  The deceased was a 0 old day female neonate wh...   \n",
       "230  24001849  24001849  According to the mother of the deceased, she h...   \n",
       "231  24000702  24000702  According to the respondent, the deceased was ...   \n",
       "232  24001069  24001069  According to the respondent, the deceased was ...   \n",
       "\n",
       "    sex_cod  age_value_death age_unit_death age_group round  \n",
       "0    Female               53          Years     adult   rd1  \n",
       "1      Male               29          Years     adult   rd1  \n",
       "2    Female               27          Years     adult   rd1  \n",
       "3      Male               40          Years     adult   rd1  \n",
       "4    Female               42          Years     adult   rd1  \n",
       "..      ...              ...            ...       ...   ...  \n",
       "228  Female                7           Days       neo   rd2  \n",
       "229  Female                0           Days       neo   rd2  \n",
       "230    Male                0           Days       neo   rd2  \n",
       "231    Male                0           Days       neo   rd2  \n",
       "232    Male                0           Days       neo   rd2  \n",
       "\n",
       "[11887 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill sex_cod NaN with empty string\n",
    "final_df['sex_cod'] = final_df['sex_cod'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling: False\n",
      "Shape of final dataframe: (11887, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>rowid</th>\n",
       "      <th>open_narrative</th>\n",
       "      <th>sex_cod</th>\n",
       "      <th>age_value_death</th>\n",
       "      <th>age_unit_death</th>\n",
       "      <th>age_group</th>\n",
       "      <th>round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>14002348</td>\n",
       "      <td>14002348</td>\n",
       "      <td>According to the respondent the deceased was w...</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>Years</td>\n",
       "      <td>adult</td>\n",
       "      <td>rd1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid     rowid                                     open_narrative  \\\n",
       "1903  14002348  14002348  According to the respondent the deceased was w...   \n",
       "\n",
       "     sex_cod  age_value_death age_unit_death age_group round  \n",
       "1903    Male               65          Years     adult   rd1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Sampling: {PROPORTION_SAMPLING}\")\n",
    "print(f\"Shape of final dataframe: {final_df.shape}\")\n",
    "final_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to healsl_dataset_all_240309_040141.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now(TIMEZONE)\n",
    "formatted_time = current_time.strftime(\"%y%m%d_%H%M%S\")\n",
    "\n",
    "temp_output_file = OUTPUT_FILE\n",
    "\n",
    "if PROPORTION_SAMPLING:\n",
    "    temp_output_file = temp_output_file.replace(\".csv\", f\"_sampled.csv\")\n",
    "temp_output_file = temp_output_file.replace(\".csv\", f\"_{formatted_time}.csv\")\n",
    "\n",
    "try:\n",
    "    final_df.to_csv(temp_output_file, index=False)\n",
    "\n",
    "    print(f\"Output saved to {temp_output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to {temp_output_file}. Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rapid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
