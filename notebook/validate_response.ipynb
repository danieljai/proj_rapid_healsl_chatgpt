{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating responses from the API\n",
    "# 100 samples for 10 requests each. 1000 samples in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyl\\AppData\\Local\\Temp\\ipykernel_41620\\2435008429.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import textwrap\n",
    "import datetime\n",
    "import pytz\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "open_api_key = os.environ.get('OPEN_API_KEY')\n",
    "client = OpenAI(api_key=open_api_key)\n",
    "\n",
    "WORDWRAP_WIDTH = 100\n",
    "DATA_FILE = \"response_validation_data_storage.json\"\n",
    "SAVE_FREQ = 5\n",
    "N_REPEAT_RESPONSES = 10\n",
    "N_SAMPLES = 100  # Replace X with the desired number of values to select\n",
    "# 100 SAMPLES\n",
    "# 10 times per sample\n",
    "\n",
    "# Models\n",
    "GPT4 = \"gpt-4-0613\"\n",
    "GPT3 = \"gpt-3.5-turbo-0125\"\n",
    "MODEL_NAME = GPT3\n",
    "\n",
    "# Set the timezone to Eastern Time\n",
    "TIMEZONE = pytz.timezone('US/Eastern')\n",
    "\n",
    "SYS_PROMPT = \"\"\"You are a physician with expertise in determining underlying causes of death in Sierra Leone by assigning ICD-10 codes for deaths using verbal autopsy narratives. Return only the ICD-10 code without description. E.g. A00 \n",
    "If there are multiple ICD-10 codes, show one code per line.\"\"\"\n",
    "\n",
    "USR_PROMPT = \"\"\"With the highest certainty, determine the underlying cause of death and provide the most accurate ICD-10 code for a verbal autopsy narrative of a AGE_VALUE_DEATH AGE_UNIT_DEATH old SEX_COD death in Sierra Leone: {open_narrative}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyl\\AppData\\Local\\Temp\\ipykernel_41620\\959988519.py:10: DtypeWarning: Columns (2,105,205,206,215,216,316) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n",
      "C:\\Users\\andyl\\AppData\\Local\\Temp\\ipykernel_41620\\959988519.py:10: DtypeWarning: Columns (182,245) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: rd1        age group: adult      len: 4987      \n",
      "round: rd1        age group: child      len: 2998      \n",
      "round: rd1        age group: neo        len: 585       \n",
      "round: rd2        age group: adult      len: 2025      \n",
      "round: rd2        age group: child      len: 1059      \n",
      "round: rd2        age group: neo        len: 233       \n"
     ]
    }
   ],
   "source": [
    "path_prefix = \"../data_202402/\"\n",
    "merged_all_df = pd.DataFrame()\n",
    "\n",
    "rounds = ['rd1', 'rd2']\n",
    "age_groups = ['adult', 'child', 'neo']\n",
    "\n",
    "for r in rounds:\n",
    "    for a in age_groups:\n",
    "        \n",
    "        questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n",
    "        age_df =            pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_age_v1.csv\")\n",
    "        narrative_df =      pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_narrative_v1.csv\")\n",
    "\n",
    "        narrative_df = narrative_df.rename(columns={'summary': 'open_narrative'})\n",
    "        \n",
    "        # Merge the dataframes\n",
    "        narrative_only = narrative_df[['rowid','open_narrative']]\n",
    "        sex_only = questionnaire_df[['rowid','sex_cod']]\n",
    "        age_only = age_df[['rowid','age_value_death','age_unit_death']]\n",
    "        \n",
    "        merged_df = narrative_only.merge(sex_only, on='rowid').merge(age_only, on='rowid')\n",
    "\n",
    "        # Fill in missing values with empty string\n",
    "        merged_df['sex_cod'] = merged_df['sex_cod'].fillna('')\n",
    "        \n",
    "        merged_df['group'] = f\"{a}_{r}\"\n",
    "\n",
    "        assert not merged_df.isnull().values.any(), \"Execution halted: NaN values found in merged_df\"\n",
    "\n",
    "        print(f\"round: {r.ljust(10)} age group: {a.ljust(10)} len: {str(merged_df.shape[0]).ljust(10)}\")\n",
    "        # print(f\"Sample of merged_df {merged_df.shape}:\")\n",
    "        # display(merged_df.sample(5))\n",
    "        \n",
    "        merged_all_df = pd.concat([merged_all_df, merged_df])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult_rd1: 42 records\n",
      "child_rd1: 25 records\n",
      "adult_rd2: 17 records\n",
      "child_rd2: 9 records\n",
      "neo_rd1: 5 records\n",
      "neo_rd2: 2 records\n"
     ]
    }
   ],
   "source": [
    "sampling_frac = ((merged_all_df.value_counts('group') / len(merged_all_df)) * N_SAMPLES).round(0).astype(int).to_dict()\n",
    "sample_ids = {}\n",
    "\n",
    "for sample in sampling_frac:\n",
    "    sample_ids[sample] = merged_all_df[merged_all_df['group'] == sample].sample(sampling_frac[sample], random_state=1).rowid.tolist()    \n",
    "    print(f\"{sample}: {sampling_frac[sample]} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 samples. No need to remove any samples.\n"
     ]
    }
   ],
   "source": [
    "sorted_sample_ids = dict(sorted(sample_ids.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "\n",
    "# Get the actual samples count\n",
    "sample_values_count = len([item for subitem in sorted_sample_ids.values() for item in subitem])\n",
    "\n",
    "# If the sample values count is greater than 100, remove the excess samples\n",
    "if sample_values_count > N_SAMPLES: \n",
    "    excess = sample_values_count - N_SAMPLES\n",
    "    print(f\"There are more than {N_SAMPLES} samples. Removing excess samples.\")\n",
    "    \n",
    "    # Iterate through the dictionary and remove the excess samples\n",
    "    for _ in range(excess):\n",
    "        for key in sorted_sample_ids:\n",
    "            \n",
    "            # If list has sufficient samples, remove the last item\n",
    "            if len(sorted_sample_ids[key]) > 10:\n",
    "                sorted_sample_ids[key].pop()\n",
    "                break\n",
    "else:\n",
    "    print(f\"There are {sample_values_count} samples. No need to remove any samples.\")\n",
    "    \n",
    "# Flatten the dictionary\n",
    "sample_ids_list = [item for sublist in sorted_sample_ids.values() for item in sublist]\n",
    "\n",
    "# Compile the final dataframe based on the sample_ids_list\n",
    "random_rowids = merged_all_df[merged_all_df['rowid'].isin(sample_ids_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Initialize the data storage dictionary\n",
    "\n",
    "def load_data(filename=DATA_FILE):\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{filename} found. Loading data...\")\n",
    "        with open(filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"{filename} not found. Initializing empty dictionary...\")\n",
    "        return {}\n",
    "\n",
    "def save_data(data, filename=DATA_FILE):\n",
    "    # Save data to a file    \n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Send a message to the chatbot\n",
    "def get_completion(\n",
    "    messages: list[dict[str, str]],\n",
    "    model: str = \"gpt-3.5-turbo-0125\",\n",
    "    # model: str = \"gpt-3.5-turbo-0125\",\n",
    "    # max_tokens=500,\n",
    "    temperature=0,\n",
    "    # stop=None,\n",
    "    # seed=123,\n",
    "    tools=None,\n",
    "    logprobs=None,\n",
    "    top_logprobs=None,\n",
    ") -> str:\n",
    "\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        # \"response_format\": { \"type\": \"json_object\" },\n",
    "        \"messages\": messages,\n",
    "        # \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        # \"stop\": stop,\n",
    "        # \"seed\": seed,\n",
    "        \"logprobs\": logprobs,\n",
    "        \"top_logprobs\": top_logprobs,\n",
    "    }\n",
    "    if tools:\n",
    "        params[\"tools\"] = tools\n",
    "\n",
    "    completion = client.chat.completions.create(**params)\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_validation_data_storage.json not found. Initializing empty dictionary...\n",
      "\n",
      "Saving count: 1000     Processing: 24000133     Rows skipped: 0\r"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# Load existing data or initialize an empty dictionary\n",
    "data_storage = load_data()\n",
    "skipped_rows = []\n",
    "repeated_skips = False\n",
    "count = 0\n",
    "print()\n",
    "\n",
    "for rp in range(N_REPEAT_RESPONSES):\n",
    "    for _, row in random_rowids.iterrows():\n",
    "        # Access the values of each column in the current row\n",
    "        # hijacking row \n",
    "        # row = merged_df[merged_df['rowid'] == 14005966].iloc[0]\n",
    "        \n",
    "        rowid = row['rowid']        \n",
    "        u_rowid = f\"{rowid}_{rp}\"\n",
    "        \n",
    "        # # Check if rowid already processed. Testing both because json changes int keys to str    \n",
    "        if (u_rowid) in data_storage or str(u_rowid) in data_storage:\n",
    "            if repeated_skips:\n",
    "                print(\"\\r\", end='', flush=True)\n",
    "            print(f\"Skipping count {count}, row {rowid} - Already processed.\", end='', flush=True)\n",
    "            repeated_skips = True\n",
    "            skipped_rows.append(rowid)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        narrative = row['open_narrative']\n",
    "        sex_cod = row['sex_cod']\n",
    "        age_value_death = row['age_value_death']\n",
    "        age_unit_death = row['age_unit_death']\n",
    "        \n",
    "        prompt = USR_PROMPT\n",
    "        prompt = prompt.replace('AGE_VALUE_DEATH', str(age_value_death))\n",
    "        prompt = prompt.replace('AGE_UNIT_DEATH', age_unit_death.lower())\n",
    "        prompt = prompt.replace('SEX_COD', sex_cod.lower())\n",
    "        prompt = prompt.format(open_narrative=narrative)\n",
    "        \n",
    "        # print(\"Prompt:\")    \n",
    "        # print(textwrap.fill(prompt, width=WORDWRAP_WIDTH))\n",
    "        # print()\n",
    "        \n",
    "        # for a in range(5):\n",
    "        completion = get_completion(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ] ,\n",
    "            model=MODEL_NAME,\n",
    "            logprobs=True,\n",
    "            # top_logprobs=2,\n",
    "        )\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        # print(completion.choices[0].message)\n",
    "        \n",
    "        # for token in completion.choices[0].logprobs.content:\n",
    "        #     print(f\"{repr(str(token.token)).ljust(15)}  {str(token.logprob).ljust(20)} {np.round(np.exp(token.logprob)*100,2)}%\")\n",
    "            \n",
    "        output_msg = completion.choices[0].message.content\n",
    "        logprob_data = [(token.token, float(token.logprob)) for token in completion.choices[0].logprobs.content]\n",
    "        usage_data = list(completion.usage)    \n",
    "        current_time = datetime.datetime.now(tz=TIMEZONE).isoformat()\n",
    "        \n",
    "        data_storage[str(u_rowid)] = {\n",
    "            'rowid': rowid,\n",
    "            'u_rowid': u_rowid,\n",
    "            'model': MODEL_NAME,\n",
    "            'system_prompt': SYS_PROMPT,\n",
    "            'user_prompt': prompt,\n",
    "            'output_msg': output_msg,\n",
    "            'logprobs': logprob_data,\n",
    "            'usage': usage_data,\n",
    "            'timestamp': current_time\n",
    "        }\n",
    "\n",
    "        # Save data periodically (you can adjust the frequency based on your needs)    \n",
    "        if count % SAVE_FREQ == 0 and count > 0:\n",
    "            if repeated_skips:\n",
    "                print(\"\\n\", flush=True)\n",
    "            repeated_skips = False\n",
    "            \n",
    "            save_data(data_storage)\n",
    "            print(f\"Saving count: {str(count).ljust(8)} Processing: {str(rowid).ljust(12)} Rows skipped: {len(skipped_rows)}\", sep=' ', end='\\r', flush=True)\n",
    "            # break\n",
    "        \n",
    "    try:\n",
    "        save_data(data_storage)\n",
    "        print(f\"Saving count: {str(count).ljust(8)} Processing: {str(rowid).ljust(12)} Rows skipped: {len(skipped_rows)}\", sep=' ', end='\\r', flush=True)\n",
    "        # print(\"\\nData saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data: {e}\")\n",
    "\n",
    "if len(skipped_rows) > 0:\n",
    "    print(f\"DF length: {len(merged_df)}\")\n",
    "    print(f\"Rows skipped: {len(skipped_rows)}\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rapid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
