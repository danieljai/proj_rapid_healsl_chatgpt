{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# parse_json.ipynb\\n\\nThis code parses JSON data created by the file that generates responses using the OpenAI API. \\nIts primary function is to extract ICD-10 codes and their associated probabilities from the JSON data \\nand format the output into a pandas DataFrame.\\n\\nThe JSON data contains the following fields:\\n\\n- `rowid`: A unique identifier for each row, similar to the identifier used in HEALSL data.\\n- `cause1_icd10`: The primary ICD-10 code.\\n- `cause1_icd10_prob`: The probability associated with the primary ICD-10 code (range: 0-1).\\n- `cause2_icd10`: The secondary ICD-10 code (optional).\\n- `cause2_icd10_prob`: The probability associated with the secondary ICD-10 code (optional).\\n- `cause3_icd10`: The tertiary ICD-10 code (optional).\\n- `cause3_icd10_prob`: The probability associated with the tertiary ICD-10 code (optional).\\n- `cause4_icd10`, `cause4_icd10_prob`, `cause5_icd10`, `cause5_icd10_prob`: \\n        Additional ICD-10 codes and their associated probabilities (optional).\\n- `output_timestamp`: The timestamp when the output was generated.\\n- `output_model`: The model used to generate the output.\\n- `output_system_prompt`: The system prompt used to generate the output.\\n- `output_user_prompt`: The user prompt used to generate the output.\\n- `output_usage_completion_tokens`: The number of completion tokens used.\\n- `output_usage_prompt_tokens`: The number of prompt tokens used.\\n- `output_msg`: The raw output returned by the OpenAI API.\\n\\nThe `output` field is a list of dictionaries. Each dictionary represents an ICD-10 code and associated data \\nextracted from `output_msg`. Here's a breakdown of the dictionary structure:\\n\\n- `icd`: An extracted ICD-10 code.\\n- `icd_linprob_mean`: The mean linear probability of the extracted ICD-10 code.\\n        This is calculated by converting the log probabilities of all tokens that compose the ICD-10 code \\n        back to linear probabilities and then taking the mean.\\n- `logprobs`: A dictionary of all tokens that compose the ICD-10 code and their log probabilities.\\n        - `token`: The token itself.\\n        - `logprob`: The log probability of the token.\\n\\nFor example, given the following `output_msg`:\\nJ18.9\\nR60.9\\nR10.4\\n\\nThe `output` produced is:\\n[{'icd': 'J18.9',\\n  'icd_linprob_mean': 0.7436831741851213,\\n  'logprobs': {'token': ['J', '18', '.', '9'],\\n   'logprob': [-0.09348458, -0.4651886, -0.8219949, -0.0035963869]}},\\n {'icd': 'R60.9',\\n  'icd_linprob_mean': 0.760383776928103,\\n  'logprobs': {'token': ['R', '60', '.', '9'],\\n   'logprob': [-0.88291967, -0.20200534, -0.0005493374, -0.20896938]}},\\n {'icd': 'R10.4',\\n  'icd_linprob_mean': 0.6912214480428616,\\n  'logprobs': {'token': ['R', '10', '.', '4'],\\n   'logprob': [-0.69898874, -1.1874909, -5.6769813e-06, -0.03789068]}}]\\n\\nThe first dictionary in the list represents the ICD-10 code 'J18.9'. \\nThe mean linear probability of this code is approximately 0.744. \\nThe log probabilities of the individual tokens 'J', '18', '.', and '9' \\nare -0.093, -0.465, -0.822, and -0.004, respectively.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# parse_json.ipynb\n",
    "\n",
    "This code parses JSON data created by the file that generates responses using the OpenAI API. \n",
    "Its primary function is to extract ICD-10 codes and their associated probabilities from the JSON data \n",
    "and format the output into a pandas DataFrame.\n",
    "\n",
    "The JSON data contains the following fields:\n",
    "\n",
    "- `rowid`: A unique identifier for each row, similar to the identifier used in HEALSL data.\n",
    "- `cause1_icd10`: The primary ICD-10 code.\n",
    "- `cause1_icd10_prob`: The probability associated with the primary ICD-10 code (range: 0-1).\n",
    "- `cause2_icd10`: The secondary ICD-10 code (optional).\n",
    "- `cause2_icd10_prob`: The probability associated with the secondary ICD-10 code (optional).\n",
    "- `cause3_icd10`: The tertiary ICD-10 code (optional).\n",
    "- `cause3_icd10_prob`: The probability associated with the tertiary ICD-10 code (optional).\n",
    "- `cause4_icd10`, `cause4_icd10_prob`, `cause5_icd10`, `cause5_icd10_prob`: \n",
    "        Additional ICD-10 codes and their associated probabilities (optional).\n",
    "- `output_timestamp`: The timestamp when the output was generated.\n",
    "- `output_model`: The model used to generate the output.\n",
    "- `output_system_prompt`: The system prompt used to generate the output.\n",
    "- `output_user_prompt`: The user prompt used to generate the output.\n",
    "- `output_usage_completion_tokens`: The number of completion tokens used.\n",
    "- `output_usage_prompt_tokens`: The number of prompt tokens used.\n",
    "- `output_msg`: The raw output returned by the OpenAI API.\n",
    "\n",
    "The `output` field is a list of dictionaries. Each dictionary represents an ICD-10 code and associated data \n",
    "extracted from `output_msg`. Here's a breakdown of the dictionary structure:\n",
    "\n",
    "- `icd`: An extracted ICD-10 code.\n",
    "- `icd_linprob_mean`: The mean linear probability of the extracted ICD-10 code.\n",
    "        This is calculated by converting the log probabilities of all tokens that compose the ICD-10 code \n",
    "        back to linear probabilities and then taking the mean.\n",
    "- `logprobs`: A dictionary of all tokens that compose the ICD-10 code and their log probabilities.\n",
    "        - `token`: The token itself.\n",
    "        - `logprob`: The log probability of the token.\n",
    "\n",
    "For example, given the following `output_msg`:\n",
    "J18.9\\nR60.9\\nR10.4\n",
    "\n",
    "The `output` produced is:\n",
    "[{'icd': 'J18.9',\n",
    "  'icd_linprob_mean': 0.7436831741851213,\n",
    "  'logprobs': {'token': ['J', '18', '.', '9'],\n",
    "   'logprob': [-0.09348458, -0.4651886, -0.8219949, -0.0035963869]}},\n",
    " {'icd': 'R60.9',\n",
    "  'icd_linprob_mean': 0.760383776928103,\n",
    "  'logprobs': {'token': ['R', '60', '.', '9'],\n",
    "   'logprob': [-0.88291967, -0.20200534, -0.0005493374, -0.20896938]}},\n",
    " {'icd': 'R10.4',\n",
    "  'icd_linprob_mean': 0.6912214480428616,\n",
    "  'logprobs': {'token': ['R', '10', '.', '4'],\n",
    "   'logprob': [-0.69898874, -1.1874909, -5.6769813e-06, -0.03789068]}}]\n",
    "\n",
    "The first dictionary in the list represents the ICD-10 code 'J18.9'. \n",
    "The mean linear probability of this code is approximately 0.744. \n",
    "The log probabilities of the individual tokens 'J', '18', '.', and '9' \n",
    "are -0.093, -0.465, -0.822, and -0.004, respectively.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyl\\AppData\\Local\\Temp\\ipykernel_23644\\1822594128.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Define the name of the data file\n",
    "DATA_FILE = \"data_storage.json\"\n",
    "\n",
    "# Define the number of paired ICDs and probabilities we want to capture\n",
    "PAIRS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Initialize the data storage dictionary\n",
    "\n",
    "def load_data(filename=DATA_FILE):\n",
    "    \"\"\"\n",
    "    Loads data from a JSON file.\n",
    "\n",
    "    This function checks if a file with the given filename exists. If it does, it opens the file, \n",
    "    loads the JSON data from it, and returns this data. If the file does not exist, it prints a message \n",
    "    and returns an empty dictionary.\n",
    "\n",
    "    Args:\n",
    "        filename (str, optional): The name of the file to load data from. Defaults to DATA_FILE.\n",
    "\n",
    "    Returns:\n",
    "        dict: The loaded data if the file exists, otherwise an empty dictionary.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{filename} found. Loading data...\")\n",
    "        with open(filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"{filename} not found. Initializing empty dictionary...\")\n",
    "        return {}\n",
    "\n",
    "def save_data(data, filename=DATA_FILE):\n",
    "    \"\"\"\n",
    "    Saves data to a JSON file.\n",
    "\n",
    "    This function opens a file with the given filename in write mode and writes the data to it in JSON format.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data to be saved.\n",
    "        filename (str, optional): The name of the file to save data to. Defaults to DATA_FILE.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Extract ICD probabilities from tokens\n",
    "\n",
    "def extract_icd_probabilities(logprobs, debug=False):\n",
    "    \"\"\"\n",
    "    Extracts ICD-10 codes and their associated probabilities from a list of tokens and log probabilities.\n",
    "\n",
    "    This function iterates over the list of tokens and log probabilities, concatenating tokens together \n",
    "    and checking if they match the pattern of an ICD-10 code. If a match is found, it calculates the mean \n",
    "    linear probability of the ICD-10 code and packages the ICD-10 code, mean linear probability, and \n",
    "    associated tokens and log probabilities into a dictionary. It then appends this dictionary to a list \n",
    "    of parsed ICD-10 codes.\n",
    "\n",
    "    Args:\n",
    "        logprobs (list): A list of lists, where each inner list contains a token and its associated log probability.\n",
    "        debug (bool, optional): If set to True, the function prints debug information. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains an ICD-10 code, its mean linear probability, \n",
    "              and a dictionary of associated tokens and log probabilities.\n",
    "    \"\"\"\n",
    "    parsed_icds = []\n",
    "    tmp_df = pd.DataFrame(logprobs)\n",
    "    if debug > 0:\n",
    "        print(repr(''.join(tmp_df.iloc[:,0])))\n",
    "    tmp_df_limit = len(tmp_df)\n",
    "    for pos in range(tmp_df_limit):\n",
    "        # Concatenate 2, 4, or 5 tokens to form ICD-10 codes\n",
    "        temp_concat_ANN = ''.join(tmp_df.iloc[pos:pos+2, 0]).strip()\n",
    "        temp_concat_ANN_NNN = ''.join(tmp_df.iloc[pos:pos+4, 0]).strip()\n",
    "        temp_concat_ANN_NNN_A = ''.join(tmp_df.iloc[pos:pos+5, 0]).strip()\n",
    "        \n",
    "        # Reference: https://www.webpt.com/blog/understanding-icd-10-code-structure\n",
    "        \n",
    "        # Regular expression pattern for various ICD-10 codes in the format\n",
    "        # 'ANN' (e.g., 'A10')\n",
    "        # 'ANN.NNN' (e.g., 'A10.001')\n",
    "        # 'ANN.NNNA' (e.g., 'A10.001A') \n",
    "        # Note: last alphabet valid only if there are 6 characters before it\n",
    "        pattern_ANN = r\"^[A-Z]\\d{2}$\"        \n",
    "        pattern_ANN_NNN = r\"^[A-Z]\\d{2}\\.\\d{1,3}$\"        \n",
    "        pattern_ANN_NNN_A = r\"^[A-Z]\\d{2}\\.\\d{3}[A-Z]$\"\n",
    "        \n",
    "        # Check if the concatenated tokens match the ICD-10 code patterns\n",
    "        match_ANN = re.match(pattern_ANN, temp_concat_ANN)\n",
    "        match_ANN_NNN = re.match(pattern_ANN_NNN, temp_concat_ANN_NNN)\n",
    "        match_ANN_NNN_A = re.match(pattern_ANN_NNN_A, temp_concat_ANN_NNN_A)\n",
    "        \n",
    "        # [debug] Each line will show which of the 3 patterns matched for the 3 token\n",
    "        if debug == 2:\n",
    "            print(str(pos).ljust(4), repr(temp_concat_ANN).ljust(10), ('yes' if match_ANN else 'no').ljust(15), repr(temp_concat_ANN_NNN).ljust(10), ('yes' if match_ANN_NNN else 'no').ljust(15), repr(temp_concat_ANN_NNN_A).ljust(10), ('yes' if match_ANN_NNN_A else 'no').ljust(5))\n",
    "        \n",
    "        # Check match from longest to shortest\n",
    "        # If a match is found, calculate the mean linear probability \n",
    "        # and package the ICD-10 code and associated data\n",
    "        if match_ANN_NNN_A:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+5])\n",
    "            winning_icd = temp_concat_ANN_NNN_A            \n",
    "        elif match_ANN_NNN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+4])\n",
    "            winning_icd = temp_concat_ANN_NNN            \n",
    "        elif match_ANN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+2])\n",
    "            winning_icd = temp_concat_ANN            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # [debug] Display the winning ICD-10 code and its associated data\n",
    "        if debug == 2:\n",
    "            print(f\"**** {winning_icd} - VALID ICD ****\")\n",
    "            display(winning_df)\n",
    "        \n",
    "        # Convert log probabilities to linear probabilities and calculate the mean\n",
    "        winning_mean = np.exp(winning_df.iloc[:, 1]).mean()\n",
    "        \n",
    "        # Package the ICD-10 code and associated data\n",
    "        winning_package = {\n",
    "            'icd': winning_icd,\n",
    "            'icd_linprob_mean': winning_mean,\n",
    "            'logprobs': winning_df.rename(columns={0: 'token', 1:'logprob'}).to_dict(orient='list')\n",
    "        }\n",
    "        \n",
    "        # Append the package to the list of parsed ICD-10 codes\n",
    "        parsed_icds.append(winning_package)\n",
    "    \n",
    "    # [debug] Display the parsed ICD-10 codes\n",
    "    if debug > 0:\n",
    "        display(parsed_icds) \n",
    "    \n",
    "    # Check if parsed_icds is empty\n",
    "    if not parsed_icds:\n",
    "        # If it is, raise an error and show the logprobs in question\n",
    "        raise ValueError(f\"No ICD-10 codes could be parsed from the provided logprobs: {logprobs}\")\n",
    "\n",
    "    return parsed_icds\n",
    "\n",
    "# # Uncomment the following lines to test the function. \n",
    "# # `test` is an example of the `logprobs` field from the JSON data.\n",
    "# test = [['A', -0.63648945],  ['09', -1.4643841], ['\\n', -0.9866263], ['R', -0.6599979], ['50', -1.5362289],\n",
    "#  ['.', -0.05481864],  ['9', -0.002321772], ['\\n', -0.3524723], ['R', -0.56709456], ['11', -1.263591],\n",
    "#  ['.', -0.05834798], ['0', -0.73551023], ['\\n', -0.5051807], ['R', -0.65759194], ['63', -1.0282977],\n",
    "#  ['.', -0.0006772888], ['4', -0.71002203]]\n",
    "\n",
    "# test_output = extract_icd_probabilities(test)\n",
    "# test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_storage.json found. Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data and convert to dataframe\n",
    "data_storage = load_data()\n",
    "df = pd.DataFrame(data_storage).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finding extract long outputs\n",
    "# df[df.icds.apply(lambda x: len(x)) > 2].index\n",
    "\n",
    "# # To speed up testing, we can limit rows with known abnormal output data\n",
    "# df = df.loc[['14004747', '14002839', \n",
    "#              '14002323', '14001355', '14000201', '14005633',\n",
    "#        '24000550', '24002181', '24000721', '24000129', '24000117', '24000186',\n",
    "#        '14002203', '14006139', '24003520',\n",
    "#        '14002421', '14009193', '24002598',\n",
    "#        ]]\n",
    "# df = df.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No ICD-10 codes could be parsed from the provided logprobs: [['O', -0.19885725], ['9', -1.5389912], ['A', -0.008896764], ['.', -0.5060559], ['1', -0.15009716]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract ICD-10 codes and their associated probabilities as a new column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_icd_probabilities\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\proj_rapid_healsl_chatgpt\\proj_rapid\\lib\\site-packages\\pandas\\core\\series.py:4897\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4780\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4898\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4902\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\proj_rapid_healsl_chatgpt\\proj_rapid\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\proj_rapid_healsl_chatgpt\\proj_rapid\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\proj_rapid_healsl_chatgpt\\proj_rapid\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\proj_rapid_healsl_chatgpt\\proj_rapid\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[4], line 92\u001b[0m, in \u001b[0;36mextract_icd_probabilities\u001b[1;34m(logprobs, debug)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Check if parsed_icds is empty\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parsed_icds:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# If it is, raise an error and show the logprobs in question\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo ICD-10 codes could be parsed from the provided logprobs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogprobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed_icds\n",
      "\u001b[1;31mValueError\u001b[0m: No ICD-10 codes could be parsed from the provided logprobs: [['O', -0.19885725], ['9', -1.5389912], ['A', -0.008896764], ['.', -0.5060559], ['1', -0.15009716]]"
     ]
    }
   ],
   "source": [
    "# Extract ICD-10 codes and their associated probabilities as a new column\n",
    "df['output'] = df['logprobs'].apply(extract_icd_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Showing `output_msg` that exceeds ICD length\n",
    "# abnormal_output_df = df[df['output_msg'].apply(lambda x:len(x) > 8)][['output_msg']]\n",
    "# print(f\"{abnormal_output_df.shape[0]} rowids with output_msg exceeding normal ICD length\")\n",
    "# print(\"Example:\")\n",
    "# print(abnormal_output_df.head(5))\n",
    "# # df[df['output_msg'].apply(lambda x:len(x) > 8)][['output_msg','icds','best_icd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Given a list of ICDs in form of a list of tuples, convert each ICD into 1-dimension Series\n",
    "\n",
    "def output_icds_to_cols(value, pairs=PAIRS):\n",
    "    \"\"\"\n",
    "    Converts a list of ICD-10 codes and their associated probabilities into a one-dimensional pandas Series.\n",
    "\n",
    "    This function takes a list of tuples, where each tuple contains an ICD-10 code and its associated \n",
    "    probability. It converts this list into a DataFrame, sorts the DataFrame by descending probability, \n",
    "    drops the 'logprobs' column, reshapes the DataFrame into a one-dimensional Series, and pads the Series \n",
    "    to fill a specified number of columns.\n",
    "\n",
    "    Args:\n",
    "        value (list): A list of tuples, where each tuple contains an ICD-10 code and its associated probability.\n",
    "        pairs (int, optional): The number of columns to pad the Series to. Defaults to PAIRS.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: A one-dimensional Series containing the ICD-10 codes and their associated probabilities.\n",
    "    \"\"\"\n",
    "    tmp = pd.DataFrame(value) # convert list of tuples to dataframe\n",
    "    tmp = tmp.sort_values(by=\"icd_linprob_mean\", ascending=False) # sort by descending probability\n",
    "    tmp = tmp.drop(columns=['logprobs'])\n",
    "    tmp = tmp.stack().reset_index(drop=True) # convert to 1 row\n",
    "    tmp = tmp.reindex(range(pairs*2), axis=1) # pad to fill PAIRS*2 columns\n",
    "    return tmp\n",
    "\n",
    "# Test\n",
    "# output_icds_to_cols(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['output'][154:155] #.apply(output_icds_to_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate column names for the exploded ICDs in cause{n}_icd10 and cause{n}_icd10_prob format\n",
    "icd_column_names_mapping = {i: f\"cause{i // 2 + 1}_icd10\" if i % 2 == 0 else f\"cause{i // 2 + 1}_icd10_prob\" for i in range(PAIRS*2)}\n",
    "\n",
    "# Apply the `output_icds_to_cols` function to the `output` column\n",
    "# This will explode the ICDs into separate columns\n",
    "parsed_df = df.merge(df.output.apply(output_icds_to_cols))\n",
    "                    #  .rename(columns=icd_column_names_mapping), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes usage and extracts the first 2 values into separate columns\n",
    "parsed_df = parsed_df.merge(\n",
    "    parsed_df['usage'].apply(lambda x: pd.DataFrame(x).iloc[:2,1])\n",
    "    .rename(columns={\n",
    "        0: \"output_usage_completion_tokens\",\n",
    "        1: \"output_usage_prompt_tokens\"\n",
    "        }), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping variable\n",
    "column_mapping = {\n",
    "    'model': 'output_model',\n",
    "    'system_prompt': 'output_system_prompt',\n",
    "    'user_prompt': 'output_user_prompt',\n",
    "    'user_prompt': 'output_user_prompt',\n",
    "    'timestamp': 'output_timestamp',\n",
    "}\n",
    "\n",
    "# Rename the columns using the mapping\n",
    "parsed_df = parsed_df.rename(columns=column_mapping)\n",
    "\n",
    "\n",
    "# Show only relevant columns in the final dataframe\n",
    "parsed_df[\n",
    "    ['rowid'] + \n",
    "    list(icd_column_names_mapping.values()) + \n",
    "    [\n",
    "        'output_timestamp',\n",
    "        'output_model',\n",
    "        'output_system_prompt' , \n",
    "        'output_user_prompt', \n",
    "        'output_usage_completion_tokens', \n",
    "        'output_usage_prompt_tokens', \n",
    "        'output_msg',\n",
    "        'output'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quickly test the mean of logprobs\n",
    "# np.mean(np.exp(pd.DataFrame([\n",
    "#     [\"V\", -0.80707335],\n",
    "#       [\"89\", -0.5674744],\n",
    "#       [\".\", -0.07485282],\n",
    "#       [\"2\", -0.049951375],\n",
    "#     ]).iloc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed_df[\n",
    "#     ['rowid'] + \n",
    "#     list(icd_column_names_mapping.values()) + \n",
    "#     [\n",
    "#         'output_timestamp',\n",
    "#         'output_model',\n",
    "#         'output_system_prompt' , \n",
    "#         'output_user_prompt', \n",
    "#         'output_usage_completion_tokens', \n",
    "#         'output_usage_prompt_tokens', \n",
    "#         'output_msg',\n",
    "#         'output'\n",
    "#     ]\n",
    "# ].loc[:, 'output'].iloc[11]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rapid_healsl_chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
