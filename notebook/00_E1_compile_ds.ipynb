{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script extracts and combines neccessary features from various datasets into one dataset.\n",
    "\n",
    "\n",
    "Pseudo code\n",
    "-----------\n",
    "1. Generate file names based on the pattern into individual dataframes.\n",
    "2. Extract the necessary features from each dataframe.\n",
    "3. Merge extracted features into a single dataframe using the rowid as the key.\n",
    "4. If PROPORTIONAL_SAMPLING is True\n",
    "    4.1. Calculate the proportion of each age group in the dataset.\n",
    "    4.2. Use the proportion to sample the dataset.\n",
    "    4.3. Handle oversampling\n",
    "5. Create unique id (uid) for each row\n",
    "    5.1 If PROPORTIONAL_SAMPLING is True, uid = f\"{age_group}_{rowid}\"\n",
    "6. Save the dataset to a file\n",
    "\n",
    "\n",
    "\n",
    "Details regarding #1 of the pseudo code:\n",
    "----------------------------------------\n",
    "\n",
    "In the context of this project, the HEALSL datset provides verbal autopsy data split into multiple \n",
    "different files. Round one and round two; adult, child, and neonate; and questionnaire, age, and \n",
    "open narrative are all separate files. The script extracts the deceased's sex from the questionnaire \n",
    "dataset, the deceased's age from the age dataset, and the open narrative recorded from the verbal \n",
    "autopsy from the narrative dataset. Then, we combine the extracted features (columns) using their \n",
    "row id as the key.\n",
    "\n",
    "    variables:\n",
    "    rounds (r):     rd1, rd2\n",
    "    age_groups (a): adult, child, neo\n",
    "\n",
    "    pattern\n",
    "    questionnaire:  healsl_{r}_{a}_v1.csv\n",
    "    age data:       healsl_{r}_{a}_age_v1.csv\n",
    "    narrative data: healsl_{r}_{a}_narrative_v1.csv\n",
    "\n",
    "    This will result in 12 files for each round of data.\n",
    "    e.g.\n",
    "    healsl_rd1_neo_v1.csv\n",
    "    healsl_rd1_neo_age_v1.csv\n",
    "    healsl_rd1_neo_narrative_v1.csv\n",
    "    ...\n",
    "    healsl_rd2_adult_v1.csv\n",
    "    healsl_rd2_adult_age_v1.csv\n",
    "    healsl_rd2_adult_narrative_v1.csv\n",
    "\n",
    "\n",
    "Details regarding #4 of the pseudo code:\n",
    "----------------------------------------\n",
    "\n",
    "    The setting complements with experimenting the consistency of responses from the language model. \n",
    "    The idea is to repeatiedly request a response to the same question and compare the results.\n",
    "    This subroutine takes a sample proportionally based on number of records per group from the \n",
    "    original dataset.\n",
    "    \n",
    "    Due to rounding errors, oversampling may happen. This is handled by removing the extra rows\n",
    "    from the group with the highest proportion to ensure groups with the lowest samples maintains \n",
    "    their prescence.\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/dwx9rt0d03d6hmp1hj2xtrdr0000gp/T/ipykernel_24909/1982584950.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Set PROPORTIONAL_SAMPLING to True to sample the dataset proportionally, and False retain the entire dataset\n",
    "PROPORTION_SAMPLING = False\n",
    "N_REPEAT_RESPONSES = 10\n",
    "N_SAMPLES = 100  # Replace X with the desired number of values to select\n",
    "\n",
    "# Output filename after processing the dataset\n",
    "OUTPUT_FILE = \"healsl_dataset_all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/dwx9rt0d03d6hmp1hj2xtrdr0000gp/T/ipykernel_24909/97552092.py:10: DtypeWarning: Columns (2,105,205,206,215,216,316) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n",
      "/var/folders/jk/dwx9rt0d03d6hmp1hj2xtrdr0000gp/T/ipykernel_24909/97552092.py:10: DtypeWarning: Columns (182,245) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: rd1        age group: adult      len: 4987      \n",
      "round: rd1        age group: child      len: 2998      \n",
      "round: rd1        age group: neo        len: 585       \n",
      "round: rd2        age group: adult      len: 2025      \n",
      "round: rd2        age group: child      len: 1059      \n",
      "round: rd2        age group: neo        len: 233       \n",
      "\n",
      "Total length of merged_all_df: 11887\n"
     ]
    }
   ],
   "source": [
    "path_prefix = \"../data_202402/\"\n",
    "merged_all_df = pd.DataFrame()\n",
    "\n",
    "rounds = ['rd1', 'rd2']\n",
    "age_groups = ['adult', 'child', 'neo']\n",
    "\n",
    "for r in rounds:\n",
    "    for a in age_groups:\n",
    "        \n",
    "        questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n",
    "        age_df =            pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_age_v1.csv\")\n",
    "        narrative_df =      pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_narrative_v1.csv\")\n",
    "\n",
    "        narrative_df = narrative_df.rename(columns={'summary': 'open_narrative'})\n",
    "        \n",
    "        # Merge the dataframes\n",
    "        narrative_only = narrative_df[['rowid','open_narrative']]\n",
    "        sex_only = questionnaire_df[['rowid','sex_cod']]\n",
    "        age_only = age_df[['rowid','age_value_death','age_unit_death']]\n",
    "        \n",
    "        merged_df = narrative_only.merge(sex_only, on='rowid').merge(age_only, on='rowid')\n",
    "\n",
    "        # Fill in missing values with empty string\n",
    "        merged_df['sex_cod'] = merged_df['sex_cod'].fillna('')\n",
    "        \n",
    "        merged_df['group'] = f\"{a}_{r}\"\n",
    "\n",
    "        assert not merged_df.isnull().values.any(), \"Execution halted: NaN values found in merged_df\"\n",
    "\n",
    "        print(f\"round: {r.ljust(10)} age group: {a.ljust(10)} len: {str(merged_df.shape[0]).ljust(10)}\")\n",
    "        # print(f\"Sample of merged_df {merged_df.shape}:\")\n",
    "        # display(merged_df.sample(5))\n",
    "        \n",
    "        merged_all_df = pd.concat([merged_all_df, merged_df])\n",
    "\n",
    "print(\"\")        \n",
    "print(f\"Total length of merged_all_df: {len(merged_all_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a sample of the merged_all_df\n",
    "if PROPORTION_SAMPLING:    \n",
    "\n",
    "    # Get the sampling fraction\n",
    "    sampling_frac = ((merged_all_df.value_counts('group') / len(merged_all_df)) * N_SAMPLES).round(0).astype(int).to_dict()\n",
    "    \n",
    "    # Initialize the dictionary to store the sample ids\n",
    "    sample_ids = {}\n",
    "\n",
    "    # Get sample based on fraction for each group\n",
    "    for sample in sampling_frac:\n",
    "        sample_ids[sample] = merged_all_df[merged_all_df['group'] == sample].sample(sampling_frac[sample], random_state=1).rowid.tolist()    \n",
    "        print(f\"{sample}: {sampling_frac[sample]} records\")\n",
    "        \n",
    "    # Sort dict from largest group to smallest\n",
    "    sorted_sample_ids = dict(sorted(sample_ids.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "\n",
    "    # Get the actual samples count\n",
    "    sample_values_count = len([item for subitem in sorted_sample_ids.values() for item in subitem])\n",
    "\n",
    "    # If sample count is more than N_SAMPLES required, remove the excess samples\n",
    "    # starting from the group with the most samples and more than 10 samples\n",
    "    if sample_values_count > N_SAMPLES: \n",
    "        excess = sample_values_count - N_SAMPLES\n",
    "        print(f\"There are more than {N_SAMPLES} samples. Removing excess samples.\")\n",
    "                \n",
    "        for _ in range(excess):\n",
    "            for key in sorted_sample_ids:\n",
    "                \n",
    "                if len(sorted_sample_ids[key]) > 10:\n",
    "                    sorted_sample_ids[key].pop()\n",
    "                    break\n",
    "    else:\n",
    "        print(f\"There are {sample_values_count} samples. No need to remove any samples.\")\n",
    "        \n",
    "    # Flatten the sample dictionary to a list of rowids\n",
    "    sample_ids_list = [item for sublist in sorted_sample_ids.values() for item in sublist]\n",
    "\n",
    "    # Compile a dataframe based on the sample rowids\n",
    "    random_rowids = merged_all_df[merged_all_df['rowid'].isin(sample_ids_list)]\n",
    "    \n",
    "    # Construct a unique id rowid_repetition and append to the dataframe\n",
    "    final_df = pd.concat([random_rowids.assign(uid=random_rowids['rowid'].astype(str) + \"_\" + str(r)) for r in range(10)])\n",
    "\n",
    "    \n",
    "# Using full dataset\n",
    "else:\n",
    "    \n",
    "    # Duplicate rowid as uid \n",
    "    final_df = merged_all_df.assign(uid=merged_all_df['rowid'])\n",
    "\n",
    "# Reorder uid as first column for presentation\n",
    "final_df = final_df[['uid'] + [col for col in final_df.columns if col != 'uid']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling: False\n",
      "Shape of final dataframe: (11887, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>rowid</th>\n",
       "      <th>open_narrative</th>\n",
       "      <th>sex_cod</th>\n",
       "      <th>age_value_death</th>\n",
       "      <th>age_unit_death</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>14003858</td>\n",
       "      <td>14003858</td>\n",
       "      <td>According to the respondent, the deceased was ...</td>\n",
       "      <td>Female</td>\n",
       "      <td>6</td>\n",
       "      <td>Months</td>\n",
       "      <td>child_rd1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid     rowid                                     open_narrative  \\\n",
       "2242  14003858  14003858  According to the respondent, the deceased was ...   \n",
       "\n",
       "     sex_cod  age_value_death age_unit_death      group  \n",
       "2242  Female                6         Months  child_rd1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Sampling: {PROPORTION_SAMPLING}\")\n",
    "print(f\"Shape of final dataframe: {final_df.shape}\")\n",
    "final_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to healsl_dataset_all.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check if the output file already exists. If yes, use a different name.\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        TIMEZONE = pytz.timezone('US/Eastern')\n",
    "\n",
    "        current_time = datetime.datetime.now(TIMEZONE)\n",
    "        formatted_time = current_time.strftime(\"%y%m%d_%H%M%S\")\n",
    "               \n",
    "        temp_output_file = OUTPUT_FILE.replace(\".csv\", f\"_{formatted_time}.csv\")\n",
    "        \n",
    "        print(f\"{OUTPUT_FILE} already exists. Saving to {temp_output_file} instead.\")\n",
    "        final_df.to_csv(temp_output_file, index=False)\n",
    "        \n",
    "    # Save dataframe as designated output file\n",
    "    else:\n",
    "        final_df.to_csv(OUTPUT_FILE, index=False)\n",
    "        \n",
    "        print(f\"Output saved to {OUTPUT_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to {OUTPUT_FILE}. Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rapid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
