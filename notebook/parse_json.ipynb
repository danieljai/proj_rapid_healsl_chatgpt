{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# parse_json.ipynb\\n\\nThis code parses JSON data created by the file that generates responses using the OpenAI API. \\nIts primary function is to extract ICD-10 codes and their associated probabilities from the JSON data \\nand format the output into a pandas DataFrame.\\n\\nThe JSON data contains the following fields:\\n\\n- `rowid`: A unique identifier for each row, similar to the identifier used in HEALSL data.\\n- `cause1_icd10`: The primary ICD-10 code.\\n- `cause1_icd10_prob`: The probability associated with the primary ICD-10 code (range: 0-1).\\n- `cause2_icd10`: The secondary ICD-10 code (optional).\\n- `cause2_icd10_prob`: The probability associated with the secondary ICD-10 code (optional).\\n- `cause3_icd10`: The tertiary ICD-10 code (optional).\\n- `cause3_icd10_prob`: The probability associated with the tertiary ICD-10 code (optional).\\n- `cause4_icd10`, `cause4_icd10_prob`, `cause5_icd10`, `cause5_icd10_prob`: \\n        Additional ICD-10 codes and their associated probabilities (optional).\\n- `output_timestamp`: The timestamp when the output was generated.\\n- `output_model`: The model used to generate the output.\\n- `output_system_prompt`: The system prompt used to generate the output.\\n- `output_user_prompt`: The user prompt used to generate the output.\\n- `output_usage_completion_tokens`: The number of completion tokens used.\\n- `output_usage_prompt_tokens`: The number of prompt tokens used.\\n- `output_msg`: The raw output returned by the OpenAI API.\\n\\nThe `output` field is a list of dictionaries. Each dictionary represents an ICD-10 code and associated data \\nextracted from `output_msg`. Here's a breakdown of the dictionary structure:\\n\\n- `icd`: An extracted ICD-10 code.\\n- `icd_linprob_mean`: The mean linear probability of the extracted ICD-10 code.\\n        This is calculated by converting the log probabilities of all tokens that compose the ICD-10 code \\n        back to linear probabilities and then taking the mean.\\n- `logprobs`: A dictionary of all tokens that compose the ICD-10 code and their log probabilities.\\n        - `token`: The token itself.\\n        - `logprob`: The log probability of the token.\\n\\nFor example, given the following `output_msg`:\\nJ18.9\\nR60.9\\nR10.4\\n\\nThe `output` produced is:\\n[{'icd': 'J18.9',\\n  'icd_linprob_mean': 0.7436831741851213,\\n  'logprobs': {'token': ['J', '18', '.', '9'],\\n   'logprob': [-0.09348458, -0.4651886, -0.8219949, -0.0035963869]}},\\n {'icd': 'R60.9',\\n  'icd_linprob_mean': 0.760383776928103,\\n  'logprobs': {'token': ['R', '60', '.', '9'],\\n   'logprob': [-0.88291967, -0.20200534, -0.0005493374, -0.20896938]}},\\n {'icd': 'R10.4',\\n  'icd_linprob_mean': 0.6912214480428616,\\n  'logprobs': {'token': ['R', '10', '.', '4'],\\n   'logprob': [-0.69898874, -1.1874909, -5.6769813e-06, -0.03789068]}}]\\n\\nThe first dictionary in the list represents the ICD-10 code 'J18.9'. \\nThe mean linear probability of this code is approximately 0.744. \\nThe log probabilities of the individual tokens 'J', '18', '.', and '9' \\nare -0.093, -0.465, -0.822, and -0.004, respectively.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# parse_json.ipynb\n",
    "\n",
    "This code parses JSON data created by the file that generates responses using the OpenAI API. \n",
    "Its primary function is to extract ICD-10 codes and their associated probabilities from the JSON data \n",
    "and format the output into a pandas DataFrame.\n",
    "\n",
    "The JSON data contains the following fields:\n",
    "\n",
    "- `rowid`: A unique identifier for each row, similar to the identifier used in HEALSL data.\n",
    "- `cause1_icd10`: The primary ICD-10 code.\n",
    "- `cause1_icd10_prob`: The probability associated with the primary ICD-10 code (range: 0-1).\n",
    "- `cause2_icd10`: The secondary ICD-10 code (optional).\n",
    "- `cause2_icd10_prob`: The probability associated with the secondary ICD-10 code (optional).\n",
    "- `cause3_icd10`: The tertiary ICD-10 code (optional).\n",
    "- `cause3_icd10_prob`: The probability associated with the tertiary ICD-10 code (optional).\n",
    "- `cause4_icd10`, `cause4_icd10_prob`, `cause5_icd10`, `cause5_icd10_prob`: \n",
    "        Additional ICD-10 codes and their associated probabilities (optional).\n",
    "- `output_timestamp`: The timestamp when the output was generated.\n",
    "- `output_model`: The model used to generate the output.\n",
    "- `output_system_prompt`: The system prompt used to generate the output.\n",
    "- `output_user_prompt`: The user prompt used to generate the output.\n",
    "- `output_usage_completion_tokens`: The number of completion tokens used.\n",
    "- `output_usage_prompt_tokens`: The number of prompt tokens used.\n",
    "- `output_msg`: The raw output returned by the OpenAI API.\n",
    "\n",
    "The `output` field is a list of dictionaries. Each dictionary represents an ICD-10 code and associated data \n",
    "extracted from `output_msg`. Here's a breakdown of the dictionary structure:\n",
    "\n",
    "- `icd`: An extracted ICD-10 code.\n",
    "- `icd_linprob_mean`: The mean linear probability of the extracted ICD-10 code.\n",
    "        This is calculated by converting the log probabilities of all tokens that compose the ICD-10 code \n",
    "        back to linear probabilities and then taking the mean.\n",
    "- `logprobs`: A dictionary of all tokens that compose the ICD-10 code and their log probabilities.\n",
    "        - `token`: The token itself.\n",
    "        - `logprob`: The log probability of the token.\n",
    "\n",
    "For example, given the following `output_msg`:\n",
    "J18.9\\nR60.9\\nR10.4\n",
    "\n",
    "The `output` produced is:\n",
    "[{'icd': 'J18.9',\n",
    "  'icd_linprob_mean': 0.7436831741851213,\n",
    "  'logprobs': {'token': ['J', '18', '.', '9'],\n",
    "   'logprob': [-0.09348458, -0.4651886, -0.8219949, -0.0035963869]}},\n",
    " {'icd': 'R60.9',\n",
    "  'icd_linprob_mean': 0.760383776928103,\n",
    "  'logprobs': {'token': ['R', '60', '.', '9'],\n",
    "   'logprob': [-0.88291967, -0.20200534, -0.0005493374, -0.20896938]}},\n",
    " {'icd': 'R10.4',\n",
    "  'icd_linprob_mean': 0.6912214480428616,\n",
    "  'logprobs': {'token': ['R', '10', '.', '4'],\n",
    "   'logprob': [-0.69898874, -1.1874909, -5.6769813e-06, -0.03789068]}}]\n",
    "\n",
    "The first dictionary in the list represents the ICD-10 code 'J18.9'. \n",
    "The mean linear probability of this code is approximately 0.744. \n",
    "The log probabilities of the individual tokens 'J', '18', '.', and '9' \n",
    "are -0.093, -0.465, -0.822, and -0.004, respectively.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyl\\AppData\\Local\\Temp\\ipykernel_23644\\1822594128.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Define the name of the data file\n",
    "DATA_FILE = \"data_storage.json\"\n",
    "\n",
    "# Define the number of paired ICDs and probabilities we want to capture\n",
    "PAIRS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Initialize the data storage dictionary\n",
    "\n",
    "def load_data(filename=DATA_FILE):\n",
    "    \"\"\"\n",
    "    Loads data from a JSON file.\n",
    "\n",
    "    This function checks if a file with the given filename exists. If it does, it opens the file, \n",
    "    loads the JSON data from it, and returns this data. If the file does not exist, it prints a message \n",
    "    and returns an empty dictionary.\n",
    "\n",
    "    Args:\n",
    "        filename (str, optional): The name of the file to load data from. Defaults to DATA_FILE.\n",
    "\n",
    "    Returns:\n",
    "        dict: The loaded data if the file exists, otherwise an empty dictionary.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{filename} found. Loading data...\")\n",
    "        with open(filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"{filename} not found. Initializing empty dictionary...\")\n",
    "        return {}\n",
    "\n",
    "def save_data(data, filename=DATA_FILE):\n",
    "    \"\"\"\n",
    "    Saves data to a JSON file.\n",
    "\n",
    "    This function opens a file with the given filename in write mode and writes the data to it in JSON format.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data to be saved.\n",
    "        filename (str, optional): The name of the file to save data to. Defaults to DATA_FILE.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Extract ICD probabilities from tokens\n",
    "\n",
    "def extract_icd_probabilities(logprobs, debug=False):\n",
    "    \"\"\"\n",
    "    Extracts ICD-10 codes and their associated probabilities from a list of tokens and log probabilities.\n",
    "\n",
    "    This function iterates over the list of tokens and log probabilities, concatenating tokens together \n",
    "    and checking if they match the pattern of an ICD-10 code. If a match is found, it calculates the mean \n",
    "    linear probability of the ICD-10 code and packages the ICD-10 code, mean linear probability, and \n",
    "    associated tokens and log probabilities into a dictionary. It then appends this dictionary to a list \n",
    "    of parsed ICD-10 codes.\n",
    "\n",
    "    Args:\n",
    "        logprobs (list): A list of lists, where each inner list contains a token and its associated log probability.\n",
    "        debug (bool, optional): If set to True, the function prints debug information. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains an ICD-10 code, its mean linear probability, \n",
    "              and a dictionary of associated tokens and log probabilities.\n",
    "    \"\"\"\n",
    "    parsed_icds = []\n",
    "    tmp_df = pd.DataFrame(logprobs)\n",
    "    if debug > 0:\n",
    "        print(repr(''.join(tmp_df.iloc[:,0])))\n",
    "    tmp_df_limit = len(tmp_df)\n",
    "    for pos in range(tmp_df_limit):\n",
    "        # Concatenate 2, 4, or 5 tokens to form ICD-10 codes\n",
    "        temp_concat_ANN = ''.join(tmp_df.iloc[pos:pos+2, 0]).strip()\n",
    "        temp_concat_ANN_NNN = ''.join(tmp_df.iloc[pos:pos+4, 0]).strip()\n",
    "        temp_concat_ANN_NNN_A = ''.join(tmp_df.iloc[pos:pos+5, 0]).strip()\n",
    "        temp_concat_ANA_NNN = ''.join(tmp_df.iloc[pos:pos+5, 0]).strip()\n",
    "        \n",
    "        # Reference: https://www.webpt.com/blog/understanding-icd-10-code-structure\n",
    "        \n",
    "        # Regular expression pattern for various ICD-10 codes in the format\n",
    "        # 'ANN' (e.g., 'A10')\n",
    "        # 'ANN.NNN' (e.g., 'A10.001')\n",
    "        # 'ANN.NNNA' (e.g., 'A10.001A') \n",
    "        # Note: last alphabet valid only if there are 6 characters before it\n",
    "        # pattern_ANN = r\"^[A-Z]\\d{2}$\"\n",
    "        pattern_ANN = r\"^[A-Z]\\d[0-9A-Z]$\"\n",
    "        # pattern_ANN_NNN = r\"^[A-Z]\\d{2}\\.\\d{1,3}$\"        \n",
    "        pattern_ANN_NNN = r\"^[A-Z]\\d[0-9A-Z]\\.\\d{1,3}$\"        \n",
    "        # pattern_ANN_NNN_A = r\"^[A-Z]\\d{2}\\.\\d{3}[A-Z]$\"\n",
    "        pattern_ANN_NNN_A = r\"^[A-Z]\\d[0-9A-Z]\\.\\d{3}[A-Z]$\"        \n",
    "        \n",
    "        # Check if the concatenated tokens match the ICD-10 code patterns\n",
    "        match_ANN = re.match(pattern_ANN, temp_concat_ANN)\n",
    "        match_ANN_NNN = re.match(pattern_ANN_NNN, temp_concat_ANN_NNN)\n",
    "        match_ANN_NNN_A = re.match(pattern_ANN_NNN_A, temp_concat_ANN_NNN_A)\n",
    "        match_ANA_NNN = re.match(pattern_ANN_NNN, temp_concat_ANA_NNN)\n",
    "        \n",
    "        # [debug] Each line will show which of the 3 patterns matched for the 3 token\n",
    "        if debug == 2:\n",
    "            print(\n",
    "                str(pos).ljust(4), \n",
    "                repr(temp_concat_ANN).ljust(10), \n",
    "                ('yes' if match_ANN else 'no').ljust(15), \n",
    "                repr(temp_concat_ANN_NNN).ljust(10), \n",
    "                ('yes' if match_ANN_NNN else 'no').ljust(15), \n",
    "                repr(temp_concat_ANN_NNN_A).ljust(10), \n",
    "                ('yes' if match_ANN_NNN_A else 'no').ljust(15),\n",
    "                repr(temp_concat_ANA_NNN).ljust(10), \n",
    "                ('yes' if match_ANA_NNN else 'no').ljust(5)\n",
    "                )\n",
    "        \n",
    "        # Check match from longest to shortest\n",
    "        # If a match is found, calculate the mean linear probability \n",
    "        # and package the ICD-10 code and associated data\n",
    "        if match_ANN_NNN_A:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+5])\n",
    "            winning_icd = temp_concat_ANN_NNN_A\n",
    "        elif match_ANA_NNN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+5])\n",
    "            winning_icd = temp_concat_ANA_NNN\n",
    "        elif match_ANN_NNN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+4])\n",
    "            winning_icd = temp_concat_ANN_NNN            \n",
    "        elif match_ANN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+2])\n",
    "            winning_icd = temp_concat_ANN            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # [debug] Display the winning ICD-10 code and its associated data\n",
    "        if debug == 2:\n",
    "            print(f\"**** {winning_icd} - VALID ICD ****\")\n",
    "            display(winning_df)\n",
    "        \n",
    "        # Convert log probabilities to linear probabilities and calculate the mean\n",
    "        winning_mean = np.exp(winning_df.iloc[:, 1]).mean()\n",
    "        \n",
    "        # Package the ICD-10 code and associated data\n",
    "        winning_package = {\n",
    "            'icd': winning_icd,\n",
    "            'icd_linprob_mean': winning_mean,\n",
    "            'logprobs': winning_df.rename(columns={0: 'token', 1:'logprob'}).to_dict(orient='list')\n",
    "        }\n",
    "        \n",
    "        # Append the package to the list of parsed ICD-10 codes\n",
    "        parsed_icds.append(winning_package)\n",
    "    \n",
    "    # [debug] Display the parsed ICD-10 codes\n",
    "    if debug > 0:\n",
    "        display(parsed_icds) \n",
    "    \n",
    "    # Check if parsed_icds is empty\n",
    "    if not parsed_icds:\n",
    "        # If it is, raise an error and show the logprobs in question\n",
    "        raise ValueError(f\"No ICD-10 codes could be parsed from the provided logprobs: {logprobs}\")\n",
    "\n",
    "    return parsed_icds\n",
    "\n",
    "# # Uncomment the following lines to test the function. \n",
    "# # `test` is an example of the `logprobs` field from the JSON data.\n",
    "# test = [['A', -0.63648945],  ['09', -1.4643841], ['\\n', -0.9866263], ['R', -0.6599979], ['50', -1.5362289],\n",
    "#  ['.', -0.05481864],  ['9', -0.002321772], ['\\n', -0.3524723], ['R', -0.56709456], ['11', -1.263591],\n",
    "#  ['.', -0.05834798], ['0', -0.73551023], ['\\n', -0.5051807], ['R', -0.65759194], ['63', -1.0282977],\n",
    "#  ['.', -0.0006772888], ['4', -0.71002203]]\n",
    "\n",
    "# test_output = extract_icd_probabilities(test)\n",
    "# test_output\n",
    "\n",
    "# # Uncomment to test a specific case\n",
    "# extract_icd_probabilities(df.loc['24000015', 'logprobs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_storage.json found. Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data and convert to dataframe\n",
    "data_storage = load_data()\n",
    "df = pd.DataFrame(data_storage).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finding extract long outputs\n",
    "# df[df.icds.apply(lambda x: len(x)) > 2].index\n",
    "\n",
    "# # To speed up testing, we can limit rows with known abnormal output data\n",
    "# df = df.loc[['14004747', '14002839', \n",
    "#              '14002323', '14001355', '14000201', '14005633',\n",
    "#        '24000550', '24002181', '24000721', '24000129', '24000117', '24000186',\n",
    "#        '14002203', '14006139', '24003520',\n",
    "#        '14002421', '14009193', '24002598',\n",
    "#        ]]\n",
    "# df = df.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ICD-10 codes and their associated probabilities as a new column\n",
    "df['output'] = df['logprobs'].apply(extract_icd_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Showing `output_msg` that exceeds ICD length\n",
    "# abnormal_output_df = df[df['output_msg'].apply(lambda x:len(x) > 8)][['output_msg']]\n",
    "# print(f\"{abnormal_output_df.shape[0]} rowids with output_msg exceeding normal ICD length\")\n",
    "# print(\"Example:\")\n",
    "# print(abnormal_output_df.head(5))\n",
    "# # df[df['output_msg'].apply(lambda x:len(x) > 8)][['output_msg','icds','best_icd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Given a list of ICDs in form of a list of tuples, convert each ICD into 1-dimension Series\n",
    "\n",
    "def output_icds_to_cols(value, pairs=PAIRS):\n",
    "    \"\"\"\n",
    "    Converts a list of ICD-10 codes and their associated probabilities into a one-dimensional pandas Series.\n",
    "\n",
    "    This function takes a list of tuples, where each tuple contains an ICD-10 code and its associated \n",
    "    probability. It converts this list into a DataFrame, sorts the DataFrame by descending probability, \n",
    "    drops the 'logprobs' column, reshapes the DataFrame into a one-dimensional Series, and pads the Series \n",
    "    to fill a specified number of columns.\n",
    "\n",
    "    Args:\n",
    "        value (list): A list of tuples, where each tuple contains an ICD-10 code and its associated probability.\n",
    "        pairs (int, optional): The number of columns to pad the Series to. Defaults to PAIRS.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: A one-dimensional Series containing the ICD-10 codes and their associated probabilities.\n",
    "    \"\"\"\n",
    "    tmp = pd.DataFrame(value) # convert list of tuples to dataframe\n",
    "    tmp = tmp.sort_values(by=\"icd_linprob_mean\", ascending=False) # sort by descending probability\n",
    "    tmp = tmp.drop(columns=['logprobs'])\n",
    "    tmp = tmp.stack().reset_index(drop=True) # convert to 1 row\n",
    "    tmp = tmp.reindex(range(pairs*2), axis=1) # pad to fill PAIRS*2 columns\n",
    "    return tmp\n",
    "\n",
    "# Test\n",
    "# output_icds_to_cols(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14002658    [{'icd': 'C40.9', 'icd_linprob_mean': 0.857925...\n",
       "Name: output, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['output'][154:155] #.apply(output_icds_to_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate column names for the exploded ICDs in cause{n}_icd10 and cause{n}_icd10_prob format\n",
    "icd_column_names_mapping = {i: f\"cause{i // 2 + 1}_icd10\" if i % 2 == 0 else f\"cause{i // 2 + 1}_icd10_prob\" for i in range(PAIRS*2)}\n",
    "\n",
    "# Apply the `output_icds_to_cols` function to the `output` column\n",
    "# This will explode the ICDs into separate columns\n",
    "parsed_df = df.merge(df.output.apply(output_icds_to_cols).rename(columns=icd_column_names_mapping), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes usage and extracts the first 2 values into separate columns\n",
    "parsed_df = parsed_df.merge(\n",
    "    parsed_df['usage'].apply(lambda x: pd.DataFrame(x).iloc[:2,1])\n",
    "    .rename(columns={\n",
    "        0: \"output_usage_completion_tokens\",\n",
    "        1: \"output_usage_prompt_tokens\"\n",
    "        }), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowid</th>\n",
       "      <th>cause1_icd10</th>\n",
       "      <th>cause1_icd10_prob</th>\n",
       "      <th>cause2_icd10</th>\n",
       "      <th>cause2_icd10_prob</th>\n",
       "      <th>cause3_icd10</th>\n",
       "      <th>cause3_icd10_prob</th>\n",
       "      <th>cause4_icd10</th>\n",
       "      <th>cause4_icd10_prob</th>\n",
       "      <th>cause5_icd10</th>\n",
       "      <th>cause5_icd10_prob</th>\n",
       "      <th>output_created</th>\n",
       "      <th>output_model</th>\n",
       "      <th>output_system_prompt</th>\n",
       "      <th>output_user_prompt</th>\n",
       "      <th>output_usage_completion_tokens</th>\n",
       "      <th>output_usage_prompt_tokens</th>\n",
       "      <th>output_msg</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14002421</th>\n",
       "      <td>14002421</td>\n",
       "      <td>I10</td>\n",
       "      <td>0.511531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T14:20:38.369528-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>2</td>\n",
       "      <td>375</td>\n",
       "      <td>I10</td>\n",
       "      <td>[{'icd': 'I10', 'icd_linprob_mean': 0.51153075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14005966</th>\n",
       "      <td>14005966</td>\n",
       "      <td>S06.5</td>\n",
       "      <td>0.814364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T14:20:38.913306-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>4</td>\n",
       "      <td>294</td>\n",
       "      <td>S06.5</td>\n",
       "      <td>[{'icd': 'S06.5', 'icd_linprob_mean': 0.814364...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14001514</th>\n",
       "      <td>14001514</td>\n",
       "      <td>B54</td>\n",
       "      <td>0.811045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T14:20:39.477378-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>2</td>\n",
       "      <td>363</td>\n",
       "      <td>B54</td>\n",
       "      <td>[{'icd': 'B54', 'icd_linprob_mean': 0.81104510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14009193</th>\n",
       "      <td>14009193</td>\n",
       "      <td>I10</td>\n",
       "      <td>0.925003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T14:20:39.993528-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>2</td>\n",
       "      <td>539</td>\n",
       "      <td>I10</td>\n",
       "      <td>[{'icd': 'I10', 'icd_linprob_mean': 0.92500286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14002210</th>\n",
       "      <td>14002210</td>\n",
       "      <td>I64</td>\n",
       "      <td>0.737392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T14:20:40.480268-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>2</td>\n",
       "      <td>366</td>\n",
       "      <td>I64</td>\n",
       "      <td>[{'icd': 'I64', 'icd_linprob_mean': 0.73739210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24002039</th>\n",
       "      <td>24002039</td>\n",
       "      <td>P91.0</td>\n",
       "      <td>0.697646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T21:35:43.111606-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>4</td>\n",
       "      <td>537</td>\n",
       "      <td>P91.0</td>\n",
       "      <td>[{'icd': 'P91.0', 'icd_linprob_mean': 0.697646...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24002598</th>\n",
       "      <td>24002598</td>\n",
       "      <td>P22.9</td>\n",
       "      <td>0.753638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T21:35:43.618831-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>4</td>\n",
       "      <td>414</td>\n",
       "      <td>P22.9</td>\n",
       "      <td>[{'icd': 'P22.9', 'icd_linprob_mean': 0.753637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24001849</th>\n",
       "      <td>24001849</td>\n",
       "      <td>P91</td>\n",
       "      <td>0.660052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T21:35:44.080042-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>2</td>\n",
       "      <td>277</td>\n",
       "      <td>P91</td>\n",
       "      <td>[{'icd': 'P91', 'icd_linprob_mean': 0.66005221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24000702</th>\n",
       "      <td>24000702</td>\n",
       "      <td>P02.1</td>\n",
       "      <td>0.884035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T21:35:45.138545-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>4</td>\n",
       "      <td>463</td>\n",
       "      <td>P02.1</td>\n",
       "      <td>[{'icd': 'P02.1', 'icd_linprob_mean': 0.884035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24001069</th>\n",
       "      <td>24001069</td>\n",
       "      <td>P95.0</td>\n",
       "      <td>0.833475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15T21:35:45.630141-05:00</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>You are a physician with expertise in determin...</td>\n",
       "      <td>With the highest certainty, determine the unde...</td>\n",
       "      <td>4</td>\n",
       "      <td>470</td>\n",
       "      <td>P95.0</td>\n",
       "      <td>[{'icd': 'P95.0', 'icd_linprob_mean': 0.833474...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11887 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rowid cause1_icd10  cause1_icd10_prob cause2_icd10  \\\n",
       "14002421  14002421          I10           0.511531          NaN   \n",
       "14005966  14005966        S06.5           0.814364          NaN   \n",
       "14001514  14001514          B54           0.811045          NaN   \n",
       "14009193  14009193          I10           0.925003          NaN   \n",
       "14002210  14002210          I64           0.737392          NaN   \n",
       "...            ...          ...                ...          ...   \n",
       "24002039  24002039        P91.0           0.697646          NaN   \n",
       "24002598  24002598        P22.9           0.753638          NaN   \n",
       "24001849  24001849          P91           0.660052          NaN   \n",
       "24000702  24000702        P02.1           0.884035          NaN   \n",
       "24001069  24001069        P95.0           0.833475          NaN   \n",
       "\n",
       "          cause2_icd10_prob cause3_icd10  cause3_icd10_prob cause4_icd10  \\\n",
       "14002421                NaN          NaN                NaN          NaN   \n",
       "14005966                NaN          NaN                NaN          NaN   \n",
       "14001514                NaN          NaN                NaN          NaN   \n",
       "14009193                NaN          NaN                NaN          NaN   \n",
       "14002210                NaN          NaN                NaN          NaN   \n",
       "...                     ...          ...                ...          ...   \n",
       "24002039                NaN          NaN                NaN          NaN   \n",
       "24002598                NaN          NaN                NaN          NaN   \n",
       "24001849                NaN          NaN                NaN          NaN   \n",
       "24000702                NaN          NaN                NaN          NaN   \n",
       "24001069                NaN          NaN                NaN          NaN   \n",
       "\n",
       "          cause4_icd10_prob cause5_icd10  cause5_icd10_prob  \\\n",
       "14002421                NaN          NaN                NaN   \n",
       "14005966                NaN          NaN                NaN   \n",
       "14001514                NaN          NaN                NaN   \n",
       "14009193                NaN          NaN                NaN   \n",
       "14002210                NaN          NaN                NaN   \n",
       "...                     ...          ...                ...   \n",
       "24002039                NaN          NaN                NaN   \n",
       "24002598                NaN          NaN                NaN   \n",
       "24001849                NaN          NaN                NaN   \n",
       "24000702                NaN          NaN                NaN   \n",
       "24001069                NaN          NaN                NaN   \n",
       "\n",
       "                            output_created        output_model  \\\n",
       "14002421  2024-02-15T14:20:38.369528-05:00  gpt-3.5-turbo-0125   \n",
       "14005966  2024-02-15T14:20:38.913306-05:00  gpt-3.5-turbo-0125   \n",
       "14001514  2024-02-15T14:20:39.477378-05:00  gpt-3.5-turbo-0125   \n",
       "14009193  2024-02-15T14:20:39.993528-05:00  gpt-3.5-turbo-0125   \n",
       "14002210  2024-02-15T14:20:40.480268-05:00  gpt-3.5-turbo-0125   \n",
       "...                                    ...                 ...   \n",
       "24002039  2024-02-15T21:35:43.111606-05:00  gpt-3.5-turbo-0125   \n",
       "24002598  2024-02-15T21:35:43.618831-05:00  gpt-3.5-turbo-0125   \n",
       "24001849  2024-02-15T21:35:44.080042-05:00  gpt-3.5-turbo-0125   \n",
       "24000702  2024-02-15T21:35:45.138545-05:00  gpt-3.5-turbo-0125   \n",
       "24001069  2024-02-15T21:35:45.630141-05:00  gpt-3.5-turbo-0125   \n",
       "\n",
       "                                       output_system_prompt  \\\n",
       "14002421  You are a physician with expertise in determin...   \n",
       "14005966  You are a physician with expertise in determin...   \n",
       "14001514  You are a physician with expertise in determin...   \n",
       "14009193  You are a physician with expertise in determin...   \n",
       "14002210  You are a physician with expertise in determin...   \n",
       "...                                                     ...   \n",
       "24002039  You are a physician with expertise in determin...   \n",
       "24002598  You are a physician with expertise in determin...   \n",
       "24001849  You are a physician with expertise in determin...   \n",
       "24000702  You are a physician with expertise in determin...   \n",
       "24001069  You are a physician with expertise in determin...   \n",
       "\n",
       "                                         output_user_prompt  \\\n",
       "14002421  With the highest certainty, determine the unde...   \n",
       "14005966  With the highest certainty, determine the unde...   \n",
       "14001514  With the highest certainty, determine the unde...   \n",
       "14009193  With the highest certainty, determine the unde...   \n",
       "14002210  With the highest certainty, determine the unde...   \n",
       "...                                                     ...   \n",
       "24002039  With the highest certainty, determine the unde...   \n",
       "24002598  With the highest certainty, determine the unde...   \n",
       "24001849  With the highest certainty, determine the unde...   \n",
       "24000702  With the highest certainty, determine the unde...   \n",
       "24001069  With the highest certainty, determine the unde...   \n",
       "\n",
       "          output_usage_completion_tokens  output_usage_prompt_tokens  \\\n",
       "14002421                               2                         375   \n",
       "14005966                               4                         294   \n",
       "14001514                               2                         363   \n",
       "14009193                               2                         539   \n",
       "14002210                               2                         366   \n",
       "...                                  ...                         ...   \n",
       "24002039                               4                         537   \n",
       "24002598                               4                         414   \n",
       "24001849                               2                         277   \n",
       "24000702                               4                         463   \n",
       "24001069                               4                         470   \n",
       "\n",
       "         output_msg                                             output  \n",
       "14002421        I10  [{'icd': 'I10', 'icd_linprob_mean': 0.51153075...  \n",
       "14005966      S06.5  [{'icd': 'S06.5', 'icd_linprob_mean': 0.814364...  \n",
       "14001514        B54  [{'icd': 'B54', 'icd_linprob_mean': 0.81104510...  \n",
       "14009193        I10  [{'icd': 'I10', 'icd_linprob_mean': 0.92500286...  \n",
       "14002210        I64  [{'icd': 'I64', 'icd_linprob_mean': 0.73739210...  \n",
       "...             ...                                                ...  \n",
       "24002039      P91.0  [{'icd': 'P91.0', 'icd_linprob_mean': 0.697646...  \n",
       "24002598      P22.9  [{'icd': 'P22.9', 'icd_linprob_mean': 0.753637...  \n",
       "24001849        P91  [{'icd': 'P91', 'icd_linprob_mean': 0.66005221...  \n",
       "24000702      P02.1  [{'icd': 'P02.1', 'icd_linprob_mean': 0.884035...  \n",
       "24001069      P95.0  [{'icd': 'P95.0', 'icd_linprob_mean': 0.833474...  \n",
       "\n",
       "[11887 rows x 19 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the mapping variable\n",
    "column_mapping = {\n",
    "    'model': 'output_model',\n",
    "    'system_prompt': 'output_system_prompt',\n",
    "    'user_prompt': 'output_user_prompt',\n",
    "    'user_prompt': 'output_user_prompt',\n",
    "    'timestamp': 'output_created',\n",
    "}\n",
    "\n",
    "# Rename the columns using the mapping\n",
    "parsed_df = parsed_df.rename(columns=column_mapping)\n",
    "\n",
    "\n",
    "# Show only relevant columns in the final dataframe\n",
    "parsed_df[\n",
    "    ['rowid'] + \n",
    "    list(icd_column_names_mapping.values()) + \n",
    "    [\n",
    "        'output_created',\n",
    "        'output_model',\n",
    "        'output_system_prompt' , \n",
    "        'output_user_prompt', \n",
    "        'output_usage_completion_tokens', \n",
    "        'output_usage_prompt_tokens', \n",
    "        'output_msg',\n",
    "        'output'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parsed data to a JSON file\n",
    "\n",
    "parsed_df.to_json(\"data_storage_parsed_20240222.json\", orient='records')\n",
    "parsed_df.to_csv(\"data_storage_parsed_20240222.csv\", index=True)\n",
    "# df.to_json(\"data_storage_parsed.json\", orient='records')\n",
    "# df.to_csv(\"data_storage_parsed.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quickly test the mean of logprobs\n",
    "# np.mean(np.exp(pd.DataFrame([\n",
    "#     [\"V\", -0.80707335],\n",
    "#       [\"89\", -0.5674744],\n",
    "#       [\".\", -0.07485282],\n",
    "#       [\"2\", -0.049951375],\n",
    "#     ]).iloc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed_df[\n",
    "#     ['rowid'] + \n",
    "#     list(icd_column_names_mapping.values()) + \n",
    "#     [\n",
    "#         'output_timestamp',\n",
    "#         'output_model',\n",
    "#         'output_system_prompt' , \n",
    "#         'output_user_prompt', \n",
    "#         'output_usage_completion_tokens', \n",
    "#         'output_usage_prompt_tokens', \n",
    "#         'output_msg',\n",
    "#         'output'\n",
    "#     ]\n",
    "# ].loc[:, 'output'].iloc[11]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rapid_healsl_chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
