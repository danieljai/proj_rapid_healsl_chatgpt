{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script takes the raw responses from the OpenAI API, extracts the ICD-10 codes and their associated probabilities,\n",
    "\n",
    "Pseudo code\n",
    "-----------\n",
    "1. Load the data from file.\n",
    "2. Parse the feature \"logprobs\" and match with various ICD10 code patterns.\n",
    "    2.1 Extract only the tokens that forms the ICD10 code pattern and its associated probability.\n",
    "    2.2 Calculate the mean linear probability of all the tokens involved.\n",
    "    2.3 Save the ICD10 code, mean linear probability, and relevant information in to \"output_probs\"\n",
    "3. Sort ICD10 codes in \"output_probs\" by their mean linear probability in descending order.\n",
    "4. Extract the top 5 ICD10 codes and their associated mean linear probabilities into their own columns.\n",
    "5. Reorder the columns and save the dataframe to file.\n",
    "\n",
    "\n",
    "Details regarding #2.1 of the pseudo code:\n",
    "------------------------------------------\n",
    "\n",
    "Although we specified the requirements in the API prompts, the response output sometimes contain additional information, \n",
    "such as extra descriptions, multiple ICD10 codes, or other unrelated information. There are only few dozens of such cases\n",
    "in over ten thousand responses. Nevertheless, these need to be handled as there can only be one best ICD10 code. In \n",
    "general, we look into the output message, find all the ICD10 codes, calculate their mean probability, and save only ICD10 \n",
    "codes with the top 5 highest mean probabilities.\n",
    "\n",
    "\n",
    "Details regarding #2.1 of the pseudo code:\n",
    "------------------------------------------\n",
    "\n",
    "An output message may show only one ICD10 code, but behind the scenes, the code is formed by a number of tokens. For \n",
    "example, an output message of \"M54.2\" is composed of four tokens: \"M\", \"54\", \".\", and \"2\". Each token has its own log \n",
    "probability. All probabilities are recorded in the \"logprobs\" feature as an array. \n",
    "\n",
    "The mean probability of a single ICD10 code is simple to calculate as we can just take the mean of the whole array.\n",
    "However, when output message consists of multiple ICD10 codes or unrelated text, 'logprobs' must be parsed to extract \n",
    "only the relevant tokens.\n",
    "\n",
    "We use a sliding window of various sizes to match different ICD10 code pattern using regular expressions. The pattern is\n",
    "as follows:\n",
    "\n",
    "    - ANN.ANNN\n",
    "    - ANN.ANN\n",
    "    - ANN\n",
    "\n",
    "... where A is a letter and N is a number.\n",
    "\n",
    "This will allow us to capture from the most detailed ICD10 code (e.g. G83.9) to the broadest (e.g. B54).\n",
    "\n",
    "\n",
    "Details regarding #2.2 of the pseudo code:\n",
    "------------------------------------------\n",
    "The formula used for calculating the mean linear probability is:\n",
    "\n",
    "    Linear_Mean_Probability = (1/n) * sum(exp(logprob_i) for i in 1 to n)\n",
    "\n",
    "... where \"logprobs\" is a list of log probabilities associated with the tokens that form the ICD10 code.\n",
    "\n",
    "        \n",
    "Details regarding #5 of the pseudo code:\n",
    "----------------------------------------\n",
    "\n",
    "Below is the data structure of the parsed data:\n",
    "\n",
    "    dataframe() = []\n",
    "        'cause(n)_icd10': the unique identifier for the response. (n) can be 1 to 5.\n",
    "        'cause(n)_icd10_prob': the mean linear probability of the ICD10 code. (n) can be 1 to 5.\n",
    "        'output_timestamp': \n",
    "        'output_model': \n",
    "        'output_system_prompt': \n",
    "        'output_user_prompt':\n",
    "        'output_usage_completion_tokens': Number of tokens used by completion\n",
    "        'output_usage_prompt_tokens': Number of tokens used by prompt\n",
    "        'output_probs': Extracted ICD-10 codes, linear mean, and their associated token probabilities.        \n",
    "        'other_columns': columns carried over from the original dataframe. (optional; by setting)\n",
    "        'raw': the original raw response (optional; by setting)\n",
    "    ]\n",
    "    \n",
    "Notes\n",
    "- limit to 40 max-tokens\n",
    "- don't care whether the best ICD is within the max tokens\n",
    "\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "\n",
    "# return the current date and time as a string\n",
    "def get_datetime_string():\n",
    "    return datetime.now().strftime('%Y%m%d_%H%M')\n",
    "\n",
    "# File Settings\n",
    "IMPORT_O2_JSON_DATA = \"./_working_data_240315/02_(sampled)_gpt4_0315.json\"\n",
    "# OUTPUT_FILE filename is automatically generated\n",
    "\n",
    "# Data Analysis Settings\n",
    "PAIRS = 5           # Generate up to 5 ICDs\n",
    "\n",
    "# Output Settings\n",
    "DROP_EXCESS_COLUMNS = False         # Set True to remove 'other_columns' from output dataframe\n",
    "DROP_RAW = False                    # Set True to remove the 'raw' column, the original raw response, from the export file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Get export filenames based on input filename\n",
    "\n",
    "def generate_export_filename(file_path) -> tuple[str, str]:\n",
    "    '''\n",
    "    Takes a file path as input and returns a tuple containing the names of the parsed JSON and CSV files.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The full path of the input file.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str(json), str(csv)]: A tuple containing the names of the parsed JSON and CSV files.\n",
    "    '''\n",
    "    directory = os.path.dirname(file_path)\n",
    "    file = os.path.basename(file_path)\n",
    "    \n",
    "    temp = file.split(\".json\")[0]\n",
    "    temp = temp[2:]\n",
    "    \n",
    "    # return {'sorted_icd: f\"{directory}/03{temp}_parsed_sorted_ICD.csv\"}, f\"{directory}/03{temp}_parsed_first_ICD.csv\"\n",
    "            \n",
    "    return {\n",
    "        'sorted_icd': f\"{directory}/03{temp}_parsed_sorted_ICD.csv\",\n",
    "        'first_icd': f\"{directory}/03{temp}_parsed_first_ICD.csv\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Initialize the data storage dictionary\n",
    "\n",
    "def load_data(filename=IMPORT_O2_JSON_DATA):\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{filename} found. Loading data...\")\n",
    "        with open(filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"{filename} not found. Initializing empty dictionary...\")\n",
    "        return {}\n",
    "\n",
    "def save_data(data, filename=IMPORT_O2_JSON_DATA):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./_working_data_240315/02_(sampled)_gpt4_0315.json found. Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data and convert to dataframe\n",
    "data_storage = load_data()\n",
    "df = pd.DataFrame(data_storage).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Extract ICD probabilities from tokens\n",
    "\n",
    "\n",
    "def extract_icd_probabilities(logprobs, debug=False):\n",
    "    \"\"\"\n",
    "    Extracts ICD-10 codes and their associated probabilities from a list of tokens and log probabilities.\n",
    "\n",
    "    This function iterates over the list of tokens and log probabilities, concatenating tokens together \n",
    "    and checking if they match the pattern of an ICD-10 code. If a match is found, it calculates the mean \n",
    "    linear probability of the ICD-10 code and packages the ICD-10 code, mean linear probability, and \n",
    "    associated tokens and log probabilities into a dictionary. It then appends this dictionary to a list \n",
    "    of parsed ICD-10 codes.\n",
    "\n",
    "    Args:\n",
    "        logprobs (list): A list of lists, where each inner list contains a token and its associated log probability.\n",
    "        debug (bool, optional): If set to True, the function prints debug information. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains an ICD-10 code, its mean linear probability, \n",
    "              and a dictionary of associated tokens and log probabilities.\n",
    "    \"\"\"\n",
    "    parsed_icds = []\n",
    "    tmp_df = pd.DataFrame(logprobs)\n",
    "    if debug > 0:\n",
    "        print(repr(''.join(tmp_df.iloc[:,0])))\n",
    "    tmp_df_limit = len(tmp_df)\n",
    "    for pos in range(tmp_df_limit):\n",
    "        # Concatenate 2, 4, or 5 tokens to form ICD-10 codes\n",
    "        temp_concat_ANN = ''.join(tmp_df.iloc[pos:pos+2, 0]).strip()\n",
    "        temp_concat_ANN_NNN = ''.join(tmp_df.iloc[pos:pos+4, 0]).strip()\n",
    "        temp_concat_ANN_NNN_A = ''.join(tmp_df.iloc[pos:pos+5, 0]).strip()\n",
    "        temp_concat_ANA_NNN = ''.join(tmp_df.iloc[pos:pos+5, 0]).strip()\n",
    "        \n",
    "        # Reference: https://www.webpt.com/blog/understanding-icd-10-code-structure\n",
    "        \n",
    "        # Regular expression pattern for various ICD-10 codes in the format\n",
    "        # 'ANN' (e.g., 'A10')\n",
    "        # 'ANN.NNN' (e.g., 'A10.001')\n",
    "        # 'ANN.NNNA' (e.g., 'A10.001A') \n",
    "        # Note: last alphabet valid only if there are 6 characters before it\n",
    "        # pattern_ANN = r\"^[A-Z]\\d{2}$\"\n",
    "        pattern_ANN = r\"^[A-Z]\\d[0-9A-Z]$\"\n",
    "        # pattern_ANN_NNN = r\"^[A-Z]\\d{2}\\.\\d{1,3}$\"        \n",
    "        pattern_ANN_NNN = r\"^[A-Z]\\d[0-9A-Z]\\.\\d{1,3}$\"        \n",
    "        # pattern_ANN_NNN_A = r\"^[A-Z]\\d{2}\\.\\d{3}[A-Z]$\"\n",
    "        pattern_ANN_NNN_A = r\"^[A-Z]\\d[0-9A-Z]\\.\\d{3}[A-Z]$\"        \n",
    "        \n",
    "        # Check if the concatenated tokens match the ICD-10 code patterns\n",
    "        match_ANN = re.match(pattern_ANN, temp_concat_ANN)\n",
    "        match_ANN_NNN = re.match(pattern_ANN_NNN, temp_concat_ANN_NNN)\n",
    "        match_ANN_NNN_A = re.match(pattern_ANN_NNN_A, temp_concat_ANN_NNN_A)\n",
    "        match_ANA_NNN = re.match(pattern_ANN_NNN, temp_concat_ANA_NNN)\n",
    "        \n",
    "        # [debug] Each line will show which of the 3 patterns matched for the 3 token\n",
    "        if debug == 2:\n",
    "            print(\n",
    "                str(pos).ljust(4), \n",
    "                repr(temp_concat_ANN).ljust(10), \n",
    "                ('yes' if match_ANN else 'no').ljust(15), \n",
    "                repr(temp_concat_ANN_NNN).ljust(10), \n",
    "                ('yes' if match_ANN_NNN else 'no').ljust(15), \n",
    "                repr(temp_concat_ANN_NNN_A).ljust(10), \n",
    "                ('yes' if match_ANN_NNN_A else 'no').ljust(15),\n",
    "                repr(temp_concat_ANA_NNN).ljust(10), \n",
    "                ('yes' if match_ANA_NNN else 'no').ljust(5)\n",
    "                )\n",
    "        \n",
    "        # Check match from longest to shortest\n",
    "        # If a match is found, calculate the mean linear probability \n",
    "        # and package the ICD-10 code and associated data\n",
    "        if match_ANN_NNN_A:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+5])\n",
    "            winning_icd = temp_concat_ANN_NNN_A\n",
    "        elif match_ANA_NNN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+5])\n",
    "            winning_icd = temp_concat_ANA_NNN\n",
    "        elif match_ANN_NNN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+4])\n",
    "            winning_icd = temp_concat_ANN_NNN            \n",
    "        elif match_ANN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+2])\n",
    "            winning_icd = temp_concat_ANN            \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # detect any rows that are just whitespace (e.g. \\n), and drop those rows\n",
    "        whitespc_index = winning_df[winning_df.loc[:, 0].str.isspace()].index.tolist()\n",
    "        winning_df = winning_df.drop(whitespc_index)\n",
    "        \n",
    "        # [debug] Display the winning ICD-10 code and its associated data\n",
    "        if debug == 2:\n",
    "            print(f\"**** {winning_icd} - VALID ICD ****\")\n",
    "            display(winning_df)\n",
    "        \n",
    "        # Convert log probabilities to linear probabilities and calculate the mean\n",
    "        winning_mean = np.exp(winning_df.iloc[:, 1]).mean()\n",
    "        \n",
    "        # Package the ICD-10 code and associated data\n",
    "        winning_package = {\n",
    "            'icd': winning_icd,\n",
    "            'icd_linprob_mean': winning_mean,\n",
    "            'logprobs': winning_df.rename(columns={0: 'token', 1:'logprob'}).to_dict(orient='list')\n",
    "        }\n",
    "\n",
    "        # check if this ICD-10 is already in the list\n",
    "        if winning_package in parsed_icds:\n",
    "            if debug > 0:\n",
    "                logging.debug(\"Duplicate ICD-10 code found. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Append the package to the list of parsed ICD-10 codes\n",
    "        parsed_icds.append(winning_package)\n",
    "    \n",
    "    # [debug] Display the parsed ICD-10 codes\n",
    "    if debug > 0:\n",
    "        display(parsed_icds) \n",
    "    \n",
    "    # Check if parsed_icds is empty\n",
    "    if not parsed_icds:\n",
    "        # If it is, raise an error and show the logprobs in question\n",
    "        logging.warning(f\"ICD-10 code not found in this logprobs: {logprobs}\")\n",
    "        \n",
    "        # winning_package = {\n",
    "        #     'icd': 'R99',\n",
    "        #     'icd_linprob_mean': 1,\n",
    "        #     'logprobs': {'token': ['R', '99'], 'logprob': [-0.00001, -0.00001]}\n",
    "        # }\n",
    "        \n",
    "        # parsed_icds.append(winning_package)\n",
    "        # raise ValueError(f\"No ICD-10 codes could be parsed from the provided logprobs: {logprobs}\")    \n",
    "    \n",
    "    # Drop the last element if there are more than 5 ICD10 extracted.\n",
    "    if len(parsed_icds) > 5:\n",
    "        parsed_icds = parsed_icds[:-1]\n",
    "\n",
    "    return parsed_icds\n",
    "\n",
    "# # Uncomment the following lines to test the function. \n",
    "# # `test` is an example of the `logprobs` field from the JSON data.\n",
    "# test = [['A', -0.63648945],  ['09', -1.4643841], ['\\n', -0.9866263], ['R', -0.6599979], ['50', -1.5362289],\n",
    "#  ['.', -0.05481864],  ['9', -0.002321772], ['\\n', -0.3524723], ['R', -0.56709456], ['11', -1.263591],\n",
    "#  ['.', -0.05834798], ['0', -0.73551023], ['\\n', -0.5051807], ['R', -0.65759194], ['63', -1.0282977],\n",
    "#  ['.', -0.0006772888], ['4', -0.71002203]]\n",
    "\n",
    "# test_output = extract_icd_probabilities(test)\n",
    "# test_output\n",
    "\n",
    "# # Uncomment to test a specific case\n",
    "# extract_icd_probabilities\n",
    "# (df.loc['14008356_0','output']['choices'][0]['logprobs']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Given a list of ICDs in form of a list of tuples, convert each ICD into 1-dimension Series\n",
    "\n",
    "def output_icds_to_cols(value, pairs=PAIRS, sort_probs=True):\n",
    "    \"\"\"\n",
    "    Converts a list of ICD-10 codes and their associated probabilities into a one-dimensional pandas Series.\n",
    "\n",
    "    This function takes a list of tuples, where each tuple contains an ICD-10 code and its associated \n",
    "    probability. It converts this list into a DataFrame, sorts the DataFrame by descending probability, \n",
    "    drops the 'logprobs' column, reshapes the DataFrame into a one-dimensional Series, and pads the Series \n",
    "    to fill a specified number of columns.\n",
    "\n",
    "    Args:\n",
    "        value (list): A list of tuples, where each tuple contains an ICD-10 code and its associated probability.\n",
    "        pairs (int, optional): The number of columns to pad the Series to. Defaults to PAIRS.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: A one-dimensional Series containing the ICD-10 codes and their associated probabilities.\n",
    "    \"\"\"\n",
    "    if value == []:\n",
    "        return pd.Series([np.nan] * pairs * 2).astype(object)\n",
    "\n",
    "    tmp = pd.DataFrame(value) # convert list of tuples to dataframe\n",
    "    \n",
    "    if sort_probs:\n",
    "        tmp = tmp.sort_values(by=\"icd_linprob_mean\", ascending=False) # sort by descending probability\n",
    "        \n",
    "    tmp = tmp.drop(columns=['logprobs'])\n",
    "    tmp = tmp.stack().reset_index(drop=True) # convert to 1 row\n",
    "    tmp = tmp.reindex(range(pairs*2), axis=1) # pad to fill PAIRS*2 columns\n",
    "    \n",
    "\n",
    "    return tmp\n",
    "\n",
    "# Test\n",
    "# output_icds_to_cols(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_filenames = generate_export_filename(IMPORT_O2_JSON_DATA)\n",
    "EXPORT_SORTED_ICD_CSV_FILE = export_filenames['sorted_icd']\n",
    "EXPORT_FIRST_ICD_CSV_FILE = export_filenames['first_icd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unrecognized colnames\n",
    "required_colnames = ['uid', 'rowid', 'param_model', 'param_temperature',\n",
    "                     'param_logprobs', 'param_system_prompt', 'param_user_prompt',\n",
    "                     'timestamp', 'output']\n",
    "\n",
    "# Get columns names that are not required\n",
    "extra_colnames = [colname for colname in df.columns if colname not in required_colnames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    output_msg = df.output.apply(lambda x: x['choices'][0]['message']['content']),\n",
    "    output_logprobs = df.output.apply(lambda x: [(token['token'], float(token['logprob'])) for token in x['choices'][0]['logprobs']['content']]),\n",
    "    output_usage_completion_tokens = df.output.apply(lambda x: x['usage']['completion_tokens']),\n",
    "    output_usage_prompt_tokens = df.output.apply(lambda x: x['usage']['prompt_tokens'])\n",
    "    \n",
    ")\n",
    "\n",
    "# Extract ICD-10 codes and their associated probabilities to a new column\n",
    "df = df.assign(output_probs=df['output_logprobs'].apply(extract_icd_probabilities))\n",
    "\n",
    "# Count the number of ICD-10 codes in each response\n",
    "df['icd10_count'] = df['output_probs'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate column names for the exploded ICDs in cause{n}_icd10 and cause{n}_icd10_prob format\n",
    "icd_column_names_mapping = {i: f\"cause{i // 2 + 1}_icd10\" if i % 2 == 0 else f\"cause{i // 2 + 1}_icd10_prob\" for i in range(PAIRS*2)}\n",
    "\n",
    "# Apply the `output_icds_to_cols` function to the `output_probs` column\n",
    "# This will explode the ICDs into separate columns\n",
    "# parsed_df = df.merge(df.output_probs.apply(output_icds_to_cols).rename(columns=icd_column_names_mapping), left_index=True, right_index=True)\n",
    "\n",
    "# cause1...5 are filled in the order of the highest probability\n",
    "parsed_sorted_icd10_df = df.merge(df.output_probs.apply(lambda x: output_icds_to_cols(x, sort_probs=True)).rename(columns=icd_column_names_mapping), left_index=True, right_index=True)\n",
    "\n",
    "# cause1...5 are filled in the order they appear in the logprobs\n",
    "parsed_first_icd10_df = df.merge(df.output_probs.apply(lambda x: output_icds_to_cols(x, sort_probs=False)).rename(columns=icd_column_names_mapping), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'rowid', 'param_model', 'param_temperature', 'param_logprobs',\n",
       "       'param_system_prompt', 'param_user_prompt', 'timestamp', 'output',\n",
       "       'age_group', 'round', 'output_msg', 'output_logprobs',\n",
       "       'output_usage_completion_tokens', 'output_usage_prompt_tokens',\n",
       "       'output_probs', 'icd10_count', 'cause1_icd10', 'cause1_icd10_prob',\n",
       "       'cause2_icd10', 'cause2_icd10_prob', 'cause3_icd10',\n",
       "       'cause3_icd10_prob', 'cause4_icd10', 'cause4_icd10_prob',\n",
       "       'cause5_icd10', 'cause5_icd10_prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_sorted_icd10_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R63.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'I12.0',\n",
       "  'icd_linprob_mean': 0.8595338383543164,\n",
       "  'logprobs': {'token': ['I', '12', '.', '0'],\n",
       "   'logprob': [-0.059283797, -0.11453045, -8.180258e-06, -0.5043144]}},\n",
       " {'icd': 'K76.7',\n",
       "  'icd_linprob_mean': 0.7139134648352159,\n",
       "  'logprobs': {'token': ['K', '76', '.', '7'],\n",
       "   'logprob': [-0.36636382, -0.8042357, -1.9816675e-06, -0.33550695]}},\n",
       " {'icd': 'R50.9',\n",
       "  'icd_linprob_mean': 0.8049610423354654,\n",
       "  'logprobs': {'token': ['R', '50', '.', '9'],\n",
       "   'logprob': [-0.46263978, -0.5234484, -0.00024001303, -0.0020111948]}},\n",
       " {'icd': 'R63.4',\n",
       "  'icd_linprob_mean': 0.9263324364480308,\n",
       "  'logprobs': {'token': ['R', '63', '.', '4'],\n",
       "   'logprob': [-0.06300457, -0.2529098, -1.4855664e-05, -0.010184187]}},\n",
       " {'icd': 'R63.0',\n",
       "  'icd_linprob_mean': 0.7758363820003169,\n",
       "  'logprobs': {'token': ['R', '63', '.', '0'],\n",
       "   'logprob': [-0.36066207, -0.79785955, -8.776276e-06, -0.0451564]}},\n",
       " {'icd': 'R53',\n",
       "  'icd_linprob_mean': 0.5055507677707753,\n",
       "  'logprobs': {'token': ['R', '53'], 'logprob': [-1.1738085, -0.35394385]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R63.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'I12.0',\n",
       "  'icd_linprob_mean': 0.7486459334800051,\n",
       "  'logprobs': {'token': ['I', '12', '.', '0'],\n",
       "   'logprob': [-0.19359861, -0.5945167, -1.8624639e-06, -0.48002517]}},\n",
       " {'icd': 'K76.7',\n",
       "  'icd_linprob_mean': 0.6806250642559467,\n",
       "  'logprobs': {'token': ['K', '76', '.', '7'],\n",
       "   'logprob': [-0.4046402, -1.0076097, -2.1008714e-06, -0.37078124]}},\n",
       " {'icd': 'R50.9',\n",
       "  'icd_linprob_mean': 0.788408252852581,\n",
       "  'logprobs': {'token': ['R', '50', '.', '9'],\n",
       "   'logprob': [-0.43220943, -0.6790432, -0.00022153647, -0.0023235565]}},\n",
       " {'icd': 'R63.4',\n",
       "  'icd_linprob_mean': 0.918117321290755,\n",
       "  'logprobs': {'token': ['R', '63', '.', '4'],\n",
       "   'logprob': [-0.07451365, -0.28137907, -1.7239736e-05, -0.01050545]}},\n",
       " {'icd': 'R63.0',\n",
       "  'icd_linprob_mean': 0.7565178975517381,\n",
       "  'logprobs': {'token': ['R', '63', '.', '0'],\n",
       "   'logprob': [-0.3943446, -0.94907904, -1.0921943e-05, -0.035768703]}},\n",
       " {'icd': 'R53',\n",
       "  'icd_linprob_mean': 0.5210137308484936,\n",
       "  'logprobs': {'token': ['R', '53'], 'logprob': [-1.1758046, -0.3099865]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R56.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'A16.9',\n",
       "  'icd_linprob_mean': 0.7549412745065133,\n",
       "  'logprobs': {'token': ['A', '16', '.', '9'],\n",
       "   'logprob': [-0.47826242, -0.6174271, -0.001908289, -0.14794128]}},\n",
       " {'icd': 'E46',\n",
       "  'icd_linprob_mean': 0.5177382100769704,\n",
       "  'logprobs': {'token': ['E', '46'], 'logprob': [-1.0526751, -0.3761876]}},\n",
       " {'icd': 'J21.9',\n",
       "  'icd_linprob_mean': 0.7123521996760981,\n",
       "  'logprobs': {'token': ['J', '21', '.', '9'],\n",
       "   'logprob': [-0.5624804, -0.7556753, -0.00027968953, -0.21047275]}},\n",
       " {'icd': 'R56.0',\n",
       "  'icd_linprob_mean': 0.8696457208189023,\n",
       "  'logprobs': {'token': ['R', '56', '.', '0'],\n",
       "   'logprob': [-0.15237157, -0.13016531, -4.7517467e-05, -0.29839128]}},\n",
       " {'icd': 'R09.2',\n",
       "  'icd_linprob_mean': 0.8243076867458965,\n",
       "  'logprobs': {'token': ['R', '09', '.', '2'],\n",
       "   'logprob': [-0.2549476, -0.5719325, -1.2664457e-06, -0.04307318]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R63.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'I12.0',\n",
       "  'icd_linprob_mean': 0.8387875647182439,\n",
       "  'logprobs': {'token': ['I', '12', '.', '0'],\n",
       "   'logprob': [-0.04348118, -0.16591269, -1.4140442e-05, -0.59675825]}},\n",
       " {'icd': 'K76.7',\n",
       "  'icd_linprob_mean': 0.7047669164629409,\n",
       "  'logprobs': {'token': ['K', '76', '.', '7'],\n",
       "   'logprob': [-0.40434068, -0.85563546, -2.220075e-06, -0.3193239]}},\n",
       " {'icd': 'R50.9',\n",
       "  'icd_linprob_mean': 0.790847532318225,\n",
       "  'logprobs': {'token': ['R', '50', '.', '9'],\n",
       "   'logprob': [-0.51402193, -0.5655048, -0.00029840085, -0.002473159]}},\n",
       " {'icd': 'R63.4',\n",
       "  'icd_linprob_mean': 0.9202575343938686,\n",
       "  'logprobs': {'token': ['R', '63', '.', '4'],\n",
       "   'logprob': [-0.07130606, -0.27135584, -1.7954959e-05, -0.012552388]}},\n",
       " {'icd': 'R63.0',\n",
       "  'icd_linprob_mean': 0.7990392195908556,\n",
       "  'logprobs': {'token': ['R', '63', '.', '0'],\n",
       "   'logprob': [-0.34031492, -0.63670427, -8.657073e-06, -0.04543028]}},\n",
       " {'icd': 'R53',\n",
       "  'icd_linprob_mean': 0.5657417653548672,\n",
       "  'logprobs': {'token': ['R', '53'], 'logprob': [-1.078259, -0.23408285]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J45.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'J45.9',\n",
       "  'icd_linprob_mean': 0.9487856807158619,\n",
       "  'logprobs': {'token': ['J', '45', '.', '9'],\n",
       "   'logprob': [-0.05504319, -0.14052296, -0.009451235, -0.010857277]}},\n",
       " {'icd': 'I10',\n",
       "  'icd_linprob_mean': 0.9481808581608021,\n",
       "  'logprobs': {'token': ['I', '10'], 'logprob': [-0.01702128, -0.09075771]}},\n",
       " {'icd': 'J96.0',\n",
       "  'icd_linprob_mean': 0.6973696449269214,\n",
       "  'logprobs': {'token': ['J', '96', '.', '0'],\n",
       "   'logprob': [-0.65572906, -0.9181754, -0.002814744, -0.1346989]}},\n",
       " {'icd': 'R50.9',\n",
       "  'icd_linprob_mean': 0.8495021538394582,\n",
       "  'logprobs': {'token': ['R', '50', '.', '9'],\n",
       "   'logprob': [-0.56631273, -0.18474178, -0.0006089136, -0.00031615852]}},\n",
       " {'icd': 'R04.2',\n",
       "  'icd_linprob_mean': 0.7939085551183627,\n",
       "  'logprobs': {'token': ['R', '04', '.', '2'],\n",
       "   'logprob': [-0.11815869, -1.1070409, -1.3856493e-06, -0.04442748]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'A09',\n",
       "  'icd_linprob_mean': 0.9795656856537089,\n",
       "  'logprobs': {'token': ['A', '09'],\n",
       "   'logprob': [-0.00074626005, -0.04094976]}},\n",
       " {'icd': 'J22',\n",
       "  'icd_linprob_mean': 0.30538814074036125,\n",
       "  'logprobs': {'token': ['J', '22'], 'logprob': [-1.1002022, -1.2802331]}},\n",
       " {'icd': 'R50.9',\n",
       "  'icd_linprob_mean': 0.9592187309050202,\n",
       "  'logprobs': {'token': ['R', '50', '.', '9'],\n",
       "   'logprob': [-0.085616924, -0.018034976, -0.06523978, -4.036525e-05]}},\n",
       " {'icd': 'R51',\n",
       "  'icd_linprob_mean': 0.7902674742998481,\n",
       "  'logprobs': {'token': ['R', '51'], 'logprob': [-0.5415736, -0.0012978541]}},\n",
       " {'icd': 'B50',\n",
       "  'icd_linprob_mean': 0.6626379732667138,\n",
       "  'logprobs': {'token': ['B', '50'], 'logprob': [-0.19849193, -0.68258405]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J18.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'I12.0',\n",
       "  'icd_linprob_mean': 0.7733234824536765,\n",
       "  'logprobs': {'token': ['I', '12', '.', '0'],\n",
       "   'logprob': [-0.58620036, -0.0021130242, -1.0087517e-05, -0.61808187]}},\n",
       " {'icd': 'J18.9',\n",
       "  'icd_linprob_mean': 0.8131794646799151,\n",
       "  'logprobs': {'token': ['J', '18', '.', '9'],\n",
       "   'logprob': [-0.46300825, -0.1582657, -6.4444386e-05, -0.26166102]}},\n",
       " {'icd': 'R53',\n",
       "  'icd_linprob_mean': 0.5325025594749777,\n",
       "  'logprobs': {'token': ['R', '53'], 'logprob': [-0.46157458, -0.83306533]}},\n",
       " {'icd': 'R64',\n",
       "  'icd_linprob_mean': 0.5411849021257585,\n",
       "  'logprobs': {'token': ['R', '64'], 'logprob': [-0.23820716, -1.2230524]}},\n",
       " {'icd': 'R50.9',\n",
       "  'icd_linprob_mean': 0.7655547346890994,\n",
       "  'logprobs': {'token': ['R', '50', '.', '9'],\n",
       "   'logprob': [-0.1967769, -1.4185665, -0.0010841365, -0.00013214473]}},\n",
       " {'icd': 'R11',\n",
       "  'icd_linprob_mean': 0.4556114044823798,\n",
       "  'logprobs': {'token': ['R', '11'], 'logprob': [-0.42561468, -1.3553588]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P23.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'P23.9',\n",
       "  'icd_linprob_mean': 0.8228421604535032,\n",
       "  'logprobs': {'token': ['P', '23', '.', '9'],\n",
       "   'logprob': [-0.18527304, -0.61671746, -0.0038645624, -0.078356005]}},\n",
       " {'icd': 'A41.9',\n",
       "  'icd_linprob_mean': 0.6580560431139925,\n",
       "  'logprobs': {'token': ['A', '41', '.', '9'],\n",
       "   'logprob': [-1.1077374, -1.1974221, -9.849109e-06, -4.310693e-05]}},\n",
       " {'icd': 'J21.9',\n",
       "  'icd_linprob_mean': 0.6629082471756018,\n",
       "  'logprobs': {'token': ['J', '21', '.', '9'],\n",
       "   'logprob': [-1.2968919, -0.8435561, -4.9305523e-05, -0.053269897]}},\n",
       " {'icd': 'I50.9',\n",
       "  'icd_linprob_mean': 0.7667977467211441,\n",
       "  'logprobs': {'token': ['I', '50', '.', '9'],\n",
       "   'logprob': [-1.528862, -0.14139628, -0.015381669, -0.0024755395]}},\n",
       " {'icd': 'K70.9',\n",
       "  'icd_linprob_mean': 0.6977478815767088,\n",
       "  'logprobs': {'token': ['K', '70', '.', '9'],\n",
       "   'logprob': [-1.2378669, -0.67586374, -0.00013703208, -0.007619399]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'A09',\n",
       "  'icd_linprob_mean': 0.9747631819476541,\n",
       "  'logprobs': {'token': ['A', '09'], 'logprob': [-0.00061319396, -0.0511466]}},\n",
       " {'icd': 'J22',\n",
       "  'icd_linprob_mean': 0.346677683284046,\n",
       "  'logprobs': {'token': ['J', '22'], 'logprob': [-1.0042969, -1.1176322]}},\n",
       " {'icd': 'R50.9',\n",
       "  'icd_linprob_mean': 0.9730464967753444,\n",
       "  'logprobs': {'token': ['R', '50', '.', '9'],\n",
       "   'logprob': [-0.05633184, -0.007069959, -0.04705593, -2.8444882e-05]}},\n",
       " {'icd': 'R51',\n",
       "  'icd_linprob_mean': 0.7937275606164953,\n",
       "  'logprobs': {'token': ['R', '51'], 'logprob': [-0.53029317, -0.0009777903]}},\n",
       " {'icd': 'B54',\n",
       "  'icd_linprob_mean': 0.6973305375603687,\n",
       "  'logprobs': {'token': ['B', '54'], 'logprob': [-0.12193996, -0.6744048]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R56.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'A16.9',\n",
       "  'icd_linprob_mean': 0.7876525355486815,\n",
       "  'logprobs': {'token': ['A', '16', '.', '9'],\n",
       "   'logprob': [-0.46410313, -0.41124478, -0.004308107, -0.14689387]}},\n",
       " {'icd': 'E46',\n",
       "  'icd_linprob_mean': 0.5618042611510842,\n",
       "  'logprobs': {'token': ['E', '46'], 'logprob': [-0.93872166, -0.31131786]}},\n",
       " {'icd': 'J21.9',\n",
       "  'icd_linprob_mean': 0.7307602884097296,\n",
       "  'logprobs': {'token': ['J', '21', '.', '9'],\n",
       "   'logprob': [-0.53369945, -0.64114875, -0.00046033994, -0.21024847]}},\n",
       " {'icd': 'R56.0',\n",
       "  'icd_linprob_mean': 0.848775986708083,\n",
       "  'logprobs': {'token': ['R', '56', '.', '0'],\n",
       "   'logprob': [-0.1379347, -0.097457, -6.146429e-05, -0.48309943]}},\n",
       " {'icd': 'R09.2',\n",
       "  'icd_linprob_mean': 0.8239937126077306,\n",
       "  'logprobs': {'token': ['R', '09', '.', '2'],\n",
       "   'logprob': [-0.29230177, -0.54757, -1.3856493e-06, -0.029346924]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R63.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'I12.0',\n",
       "  'icd_linprob_mean': 0.7713639979852831,\n",
       "  'logprobs': {'token': ['I', '12', '.', '0'],\n",
       "   'logprob': [-0.11272752, -0.3851168, -1.5332478e-05, -0.67000484]}},\n",
       " {'icd': 'K70.9',\n",
       "  'icd_linprob_mean': 0.6072918717432707,\n",
       "  'logprobs': {'token': ['K', '70', '.', '9'],\n",
       "   'logprob': [-0.4261989, -1.0091586, -0.00017517358, -0.8871431]}},\n",
       " {'icd': 'R50.9',\n",
       "  'icd_linprob_mean': 0.8273524221318174,\n",
       "  'logprobs': {'token': ['R', '50', '.', '9'],\n",
       "   'logprob': [-0.30295455, -0.5601619, -7.767599e-05, -0.00026193185]}},\n",
       " {'icd': 'R63.4',\n",
       "  'icd_linprob_mean': 0.9163524951448951,\n",
       "  'logprobs': {'token': ['R', '63', '.', '4'],\n",
       "   'logprob': [-0.073521554, -0.28840703, -4.6563837e-05, -0.01320283]}},\n",
       " {'icd': 'R17',\n",
       "  'icd_linprob_mean': 0.4897818176039933,\n",
       "  'logprobs': {'token': ['R', '17'], 'logprob': [-0.39330685, -1.1882898]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'A09',\n",
       "  'icd_linprob_mean': 0.712999284399908,\n",
       "  'logprobs': {'token': ['A', '09'], 'logprob': [-0.24463004, -0.4416037]}},\n",
       " {'icd': 'G40',\n",
       "  'icd_linprob_mean': 0.6562899063125897,\n",
       "  'logprobs': {'token': ['G', '40'], 'logprob': [-1.1551665, -0.0024282173]}},\n",
       " {'icd': 'R56',\n",
       "  'icd_linprob_mean': 0.4188756327642587,\n",
       "  'logprobs': {'token': ['R', '56'], 'logprob': [-0.5782107, -1.2842788]}},\n",
       " {'icd': 'R53',\n",
       "  'icd_linprob_mean': 0.4313935521236462,\n",
       "  'logprobs': {'token': ['R', '53'], 'logprob': [-0.60247046, -1.1541368]}},\n",
       " {'icd': 'R63.4',\n",
       "  'icd_linprob_mean': 0.6388304828547613,\n",
       "  'logprobs': {'token': ['R', '63', '.', '4'],\n",
       "   'logprob': [-0.7492716, -1.6239448, -0.0517336, -0.06623616]}},\n",
       " {'icd': 'R63.5',\n",
       "  'icd_linprob_mean': 0.6026414282847385,\n",
       "  'logprobs': {'token': ['R', '63', '.', '5'],\n",
       "   'logprob': [-0.80144227, -0.98324984, -0.0046396917, -0.5235396]}},\n",
       " {'icd': 'R06.02',\n",
       "  'icd_linprob_mean': 0.4533704538532517,\n",
       "  'logprobs': {'token': ['R', '06', '.', '02'],\n",
       "   'logprob': [-0.96081984, -1.7241917, -0.006321928, -1.3513614]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'A09',\n",
       "  'icd_linprob_mean': 0.9881784467706127,\n",
       "  'logprobs': {'token': ['A', '09'],\n",
       "   'logprob': [-0.022954604, -0.00095040654]}},\n",
       " {'icd': 'E86',\n",
       "  'icd_linprob_mean': 0.8537254681067601,\n",
       "  'logprobs': {'token': ['E', '86'], 'logprob': [-0.29495215, -0.03782262]}},\n",
       " {'icd': 'K72.9',\n",
       "  'icd_linprob_mean': 0.7271886073885627,\n",
       "  'logprobs': {'token': ['K', '72', '.', '9'],\n",
       "   'logprob': [-0.77779555, -0.034148473, -0.0019136423, -0.7239764]}},\n",
       " {'icd': 'R57.0',\n",
       "  'icd_linprob_mean': 0.6049286154919002,\n",
       "  'logprobs': {'token': ['R', '57', '.', '0'],\n",
       "   'logprob': [-1.1260089, -0.95826876, -0.0014445223, -0.33788612]}},\n",
       " {'icd': 'R09.2',\n",
       "  'icd_linprob_mean': 0.5291197373531094,\n",
       "  'logprobs': {'token': ['R', '09', '.', '2'],\n",
       "   'logprob': [-0.79848677, -1.3784374, -3.4121115e-06, -0.88067997]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N18.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'E11.9',\n",
       "  'icd_linprob_mean': 0.5504363627977326,\n",
       "  'logprobs': {'token': ['E', '11', '.', '9'],\n",
       "   'logprob': [-0.8412005, -1.0157803, -0.037181444, -0.8098342]}},\n",
       " {'icd': 'N18.9',\n",
       "  'icd_linprob_mean': 0.7719542684814799,\n",
       "  'logprobs': {'token': ['N', '18', '.', '9'],\n",
       "   'logprob': [-0.97446537, -0.3062638, -0.0017336098, -0.02433088]}},\n",
       " {'icd': 'I12.0',\n",
       "  'icd_linprob_mean': 0.7681456216585981,\n",
       "  'logprobs': {'token': ['I', '12', '.', '0'],\n",
       "   'logprob': [-0.90316814, -0.032456398, -1.7432603e-06, -0.35776705]}},\n",
       " {'icd': 'K72.9',\n",
       "  'icd_linprob_mean': 0.7566464756615245,\n",
       "  'logprobs': {'token': ['K', '72', '.', '9'],\n",
       "   'logprob': [-1.135973, -0.29676807, -3.4121115e-06, -0.038467042]}},\n",
       " {'icd': 'R53',\n",
       "  'icd_linprob_mean': 0.5257772860892567,\n",
       "  'logprobs': {'token': ['R', '53'], 'logprob': [-0.45512187, -0.8742281]}},\n",
       " {'icd': 'R60.9',\n",
       "  'icd_linprob_mean': 0.7012935308963191,\n",
       "  'logprobs': {'token': ['R', '60', '.', '9'],\n",
       "   'logprob': [-0.5617938, -0.76205784, -0.00012106613, -0.2634386]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R56.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'icd': 'A06.4',\n",
       "  'icd_linprob_mean': 0.7330490629679691,\n",
       "  'logprobs': {'token': ['A', '06', '.', '4'],\n",
       "   'logprob': [-0.010746774, -0.890556, -0.00011248347, -0.63004005]}},\n",
       " {'icd': 'R50.9',\n",
       "  'icd_linprob_mean': 0.798805873883522,\n",
       "  'logprobs': {'token': ['R', '50', '.', '9'],\n",
       "   'logprob': [-0.98804533, -0.16709937, -0.023264816, -0.00019948746]}},\n",
       " {'icd': 'R17',\n",
       "  'icd_linprob_mean': 0.6827161117960667,\n",
       "  'logprobs': {'token': ['R', '17'], 'logprob': [-0.52139723, -0.25910527]}},\n",
       " {'icd': 'R56.0',\n",
       "  'icd_linprob_mean': 0.8634883073890831,\n",
       "  'logprobs': {'token': ['R', '56', '.', '0'],\n",
       "   'logprob': [-0.33912933, -0.20115697, -0.00032294946, -0.07893308]}},\n",
       " {'icd': 'R63.0',\n",
       "  'icd_linprob_mean': 0.6439339464690506,\n",
       "  'logprobs': {'token': ['R', '63', '.', '0'],\n",
       "   'logprob': [-0.8385104, -1.8954664, -0.0016641122, -0.0052173943]}},\n",
       " {'icd': 'R58',\n",
       "  'icd_linprob_mean': 0.23228242007528363,\n",
       "  'logprobs': {'token': ['R', '58'], 'logprob': [-1.3477597, -1.585999]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _, a in parsed_sorted_icd10_df[parsed_sorted_icd10_df.icd10_count > 3].sample(15).iterrows():\n",
    "    print(a['cause1_icd10'])\n",
    "    display(a['output_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cause1_icd10</th>\n",
       "      <th>output_logprobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14006015_0</th>\n",
       "      <td>C10.9</td>\n",
       "      <td>[(C, -0.4171243), (10, -0.22050741), (., -7.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14003152_0</th>\n",
       "      <td>A15.9</td>\n",
       "      <td>[(A, -0.0015137888), (15, -0.0008190385), (., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14004789_0</th>\n",
       "      <td>V89.2</td>\n",
       "      <td>[(V, -1.7432603e-06), (89, -0.05246823), (., -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14008356_0</th>\n",
       "      <td>R50.9</td>\n",
       "      <td>[(A, -0.23412237), (18, -0.024403129), (., -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14004298_0</th>\n",
       "      <td>K25</td>\n",
       "      <td>[(I, -0.6327079), (10, -0.09191374), (\\n, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24002603_9</th>\n",
       "      <td>G91.9</td>\n",
       "      <td>[(G, -0.0097376695), (91, -0.27452958), (., -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24002738_9</th>\n",
       "      <td>B50.0</td>\n",
       "      <td>[(B, -0.0010274507), (50, -0.00011272187), (.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24000569_9</th>\n",
       "      <td>A87</td>\n",
       "      <td>[(A, -0.09199736), (87, -0.45179173)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24002421_9</th>\n",
       "      <td>P22.0</td>\n",
       "      <td>[(P, -0.00045902873), (22, -0.11226488), (., -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24000133_9</th>\n",
       "      <td>P55.9</td>\n",
       "      <td>[(P, -0.00024977676), (55, -0.51851904), (., -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cause1_icd10                                    output_logprobs\n",
       "14006015_0        C10.9  [(C, -0.4171243), (10, -0.22050741), (., -7.89...\n",
       "14003152_0        A15.9  [(A, -0.0015137888), (15, -0.0008190385), (., ...\n",
       "14004789_0        V89.2  [(V, -1.7432603e-06), (89, -0.05246823), (., -...\n",
       "14008356_0        R50.9  [(A, -0.23412237), (18, -0.024403129), (., -1....\n",
       "14004298_0          K25  [(I, -0.6327079), (10, -0.09191374), (\\n, -0.1...\n",
       "...                 ...                                                ...\n",
       "24002603_9        G91.9  [(G, -0.0097376695), (91, -0.27452958), (., -0...\n",
       "24002738_9        B50.0  [(B, -0.0010274507), (50, -0.00011272187), (.,...\n",
       "24000569_9          A87              [(A, -0.09199736), (87, -0.45179173)]\n",
       "24002421_9        P22.0  [(P, -0.00045902873), (22, -0.11226488), (., -...\n",
       "24000133_9        P55.9  [(P, -0.00024977676), (55, -0.51851904), (., -...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_sorted_icd10_df[['cause1_icd10', 'output_logprobs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping variable\n",
    "column_mapping = {\n",
    "    'model': 'output_model',\n",
    "    'system_prompt': 'output_system_prompt',\n",
    "    'user_prompt': 'output_user_prompt',\n",
    "    'user_prompt': 'output_user_prompt',\n",
    "    'timestamp': 'output_created',\n",
    "}\n",
    "\n",
    "# Rename the columns using the mapping\n",
    "parsed_sorted_icd10_df = parsed_sorted_icd10_df.rename(columns=column_mapping)\n",
    "parsed_first_icd10_df = parsed_first_icd10_df.rename(columns=column_mapping)\n",
    "\n",
    "export_columns = []\n",
    "export_columns += ['rowid']\n",
    "export_columns += list(icd_column_names_mapping.values())\n",
    "export_columns += [\n",
    "                    'output_created',\n",
    "                    'param_model',\n",
    "                    'param_system_prompt' , \n",
    "                    'param_user_prompt', \n",
    "                    'output_usage_completion_tokens', \n",
    "                    'output_usage_prompt_tokens', \n",
    "                    'output_msg',\n",
    "                    'icd10_count',\n",
    "                    'output_probs',\n",
    "                ]\n",
    "\n",
    "if not DROP_EXCESS_COLUMNS:\n",
    "    export_columns += extra_colnames\n",
    "    \n",
    "if not DROP_RAW:\n",
    "    export_columns += ['output']\n",
    "\n",
    "\n",
    "# Show only relevant columns in the final dataframe\n",
    "export_parsed_sorted_icd10_df = parsed_sorted_icd10_df[export_columns]\n",
    "export_parsed_first_icd10_df = parsed_first_icd10_df[export_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export Dataframe shape: (11887, 23)\n",
      "Processed export_parsed_sorted_icd10_df exporting to: ./_working_data_240315/03_(all)_gpt3_0309_parsed_sorted_ICD.csv\n",
      "Processed export_parsed_first_icd10_df exporting to: ./_working_data_240315/03_(all)_gpt3_0309_parsed_first_ICD.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Export Dataframe shape: {export_parsed_sorted_icd10_df.shape}\")\n",
    "print(f\"Processed export_parsed_sorted_icd10_df exporting to: {EXPORT_SORTED_ICD_CSV_FILE}\")\n",
    "print(f\"Processed export_parsed_first_icd10_df exporting to: {EXPORT_FIRST_ICD_CSV_FILE}\")\n",
    "\n",
    "# Save the parsed data to a JSON file\n",
    "export_parsed_sorted_icd10_df.to_csv(EXPORT_SORTED_ICD_CSV_FILE, index=False)\n",
    "export_parsed_first_icd10_df.to_csv(EXPORT_FIRST_ICD_CSV_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# icd10 counts \n",
    "# export_parsed_sorted_icd10_df[export_parsed_sorted_icd10_df.icd10_count < 1]\n",
    "\n",
    "# verify that the sort is working\n",
    "# export_parsed_sorted_icd10_df[export_parsed_sorted_icd10_df.icd10_count > 2][list(icd_column_names_mapping.values()) + ['output_probs']]\n",
    "\n",
    "# verify that the non-sort is working\n",
    "# export_parsed_first_icd10_df[export_parsed_first_icd10_df.icd10_count > 2][list(icd_column_names_mapping.values()) + ['output_msg', 'output_probs']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rapid_healsl_chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
