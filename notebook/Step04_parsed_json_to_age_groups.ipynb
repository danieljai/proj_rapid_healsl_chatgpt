{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    This script splits the JSON into multiple files, according to ROWID_SPLITS use to separate round 1 and round 2 data.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This script splits the JSON into multiple files, according to ROWID_SPLITS use to separate round 1 and round 2 data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/dwx9rt0d03d6hmp1hj2xtrdr0000gp/T/ipykernel_56193/1019307687.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['03_(all)_gpt4_0313_parsed_sorted_ICD.csv',\n",
       " '03_(all)_gpt3_0309_parsed_first_ICD.csv',\n",
       " '03_(all)_gpt3_0309_parsed_sorted_ICD.csv',\n",
       " '03_(all)_gpt4_0313_parsed_first_ICD.csv']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Define the name of the data file\n",
    "WORKING_DIR = \"_working_data_240315\"\n",
    "EXPORT_DIR = f\"./{WORKING_DIR}/healsl_rd1to2_rapid_gpt_v2b_2024_03_15\"\n",
    "\n",
    "# Create the export directory if it does not exist\n",
    "if not os.path.exists(EXPORT_DIR):\n",
    "    print(f\"Creating directory: {EXPORT_DIR}\")\n",
    "    os.makedirs(EXPORT_DIR)\n",
    "    \n",
    "\n",
    "# Show working files\n",
    "files = [file for file in os.listdir('./_working_data_240315') if file.startswith('03_') and 'sampled' not in file]\n",
    "display(files)\n",
    "\n",
    "\n",
    "# IMPORT_CSV_FILE = \"./_working_data_240315/all_data_gpt4_0313_parsed_first_ICD.csv\"\n",
    "\n",
    "VERSION = \"v2b\"\n",
    "\n",
    "export_filename_template = \"healsl_ROUND_rapid_MODELNAME_{VERSION}{OPTIONS}.csv\"\n",
    "export_filename_template = export_filename_template.replace(\"{VERSION}\", VERSION)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading file: ./_working_data_240315/03_(all)_gpt4_0313_parsed_sorted_ICD.csv\n",
      "INFO:root:model name: gpt4\n",
      "INFO:root:first icd option: None\n",
      "INFO:root:sorted icd option: sorted_ICD\n",
      "INFO:root:Exporting round 1 data to: ./_working_data_240315/healsl_rd1to2_rapid_gpt_v2b_2024_03_15/healsl_rd1_rapid_gpt4_v2b_sorted_ICD.csv\n",
      "INFO:root:Exporting round 2 data to: ./_working_data_240315/healsl_rd1to2_rapid_gpt_v2b_2024_03_15/healsl_rd2_rapid_gpt4_v2b_sorted_ICD.csv\n",
      "INFO:root:Reading file: ./_working_data_240315/03_(all)_gpt3_0309_parsed_first_ICD.csv\n",
      "INFO:root:model name: gpt3\n",
      "INFO:root:first icd option: first_ICD\n",
      "INFO:root:sorted icd option: None\n",
      "INFO:root:Exporting round 1 data to: ./_working_data_240315/healsl_rd1to2_rapid_gpt_v2b_2024_03_15/healsl_rd1_rapid_gpt3_v2b_first_ICD.csv\n",
      "INFO:root:Exporting round 2 data to: ./_working_data_240315/healsl_rd1to2_rapid_gpt_v2b_2024_03_15/healsl_rd2_rapid_gpt3_v2b_first_ICD.csv\n",
      "INFO:root:Reading file: ./_working_data_240315/03_(all)_gpt3_0309_parsed_sorted_ICD.csv\n",
      "INFO:root:model name: gpt3\n",
      "INFO:root:first icd option: None\n",
      "INFO:root:sorted icd option: sorted_ICD\n",
      "INFO:root:Exporting round 1 data to: ./_working_data_240315/healsl_rd1to2_rapid_gpt_v2b_2024_03_15/healsl_rd1_rapid_gpt3_v2b_sorted_ICD.csv\n",
      "INFO:root:Exporting round 2 data to: ./_working_data_240315/healsl_rd1to2_rapid_gpt_v2b_2024_03_15/healsl_rd2_rapid_gpt3_v2b_sorted_ICD.csv\n",
      "INFO:root:Reading file: ./_working_data_240315/03_(all)_gpt4_0313_parsed_first_ICD.csv\n",
      "INFO:root:model name: gpt4\n",
      "INFO:root:first icd option: first_ICD\n",
      "INFO:root:sorted icd option: None\n",
      "INFO:root:Exporting round 1 data to: ./_working_data_240315/healsl_rd1to2_rapid_gpt_v2b_2024_03_15/healsl_rd1_rapid_gpt4_v2b_first_ICD.csv\n",
      "INFO:root:Exporting round 2 data to: ./_working_data_240315/healsl_rd1to2_rapid_gpt_v2b_2024_03_15/healsl_rd2_rapid_gpt4_v2b_first_ICD.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in files:\n",
    "    # df = pd.read_csv(f\"{WORKING_DIR}/{filename}\")\n",
    "\n",
    "    modelname = re.search(r'gpt\\d', filename).group(0)\n",
    "\n",
    "    first_icd_option = None if re.search(r'first_ICD', filename) is None else re.search(r'first_ICD', filename).group(0)\n",
    "    sorted_icd_option = None if re.search(r'sorted_ICD', filename) is None else re.search(r'sorted_ICD', filename).group(0)\n",
    "\n",
    "    final_option = None\n",
    "    if first_icd_option is not None:\n",
    "        final_option = \"_\" + first_icd_option\n",
    "    elif sorted_icd_option is not None:\n",
    "        final_option = \"_\" + sorted_icd_option\n",
    "\n",
    "    export_filename = export_filename_template.replace(\"MODELNAME\", modelname).replace(\"{OPTIONS}\", final_option)\n",
    "    export_filename = f\"{EXPORT_DIR}/{export_filename}\"\n",
    "\n",
    "    import_csv_file = f\"./{WORKING_DIR}/{filename}\"\n",
    "    logging.info(f\"Reading file: {import_csv_file}\")\n",
    "    logging.info(f\"model name: {modelname}\")\n",
    "    logging.info(f\"first icd option: {first_icd_option}\")\n",
    "    logging.info(f\"sorted icd option: {sorted_icd_option}\")\n",
    "    df = pd.read_csv(import_csv_file)\n",
    "\n",
    "    # Split the data into round 1 and round 2\n",
    "    rd1_df = df[df['round'] == \"rd1\"]\n",
    "    rd2_df = df[df['round'] == \"rd2\"]\n",
    "\n",
    "    # Export the data\n",
    "    round1_filename = export_filename.replace(\"ROUND\", \"rd1\")\n",
    "    round2_filename = export_filename.replace(\"ROUND\", \"rd2\")\n",
    "\n",
    "    logging.info(f\"Exporting round 1 data to: {round1_filename}\")\n",
    "    rd1_df.to_csv(export_filename.replace(\"ROUND\", \"rd1\"), index=False)\n",
    "\n",
    "    logging.info(f\"Exporting round 2 data to: {round2_filename}\")\n",
    "    rd2_df.to_csv(export_filename.replace(\"ROUND\", \"rd2\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(IMPORT_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['round'] == \"rd1\"].to_csv(f\"{EXPORT_DIR}/healsl_rd1_rapid_gpt3_v2b.csv\", index=False)\n",
    "df[df['round'] == \"rd2\"].to_csv(f\"{EXPORT_DIR}/healsl_rd2_rapid_gpt3_v2b.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.icd10_count > 2000].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.icd10_count > 2000].rowid.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools: Re-process df, eval from str -> list\n",
    "import ast\n",
    "df.output_probs = df.output_probs.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Count the number of elements in the list\n",
    "\n",
    "# df.output_probs.apply(lambda x: len(x)).value_counts(ascending=)\n",
    "print(f\"Number of ICDs returned per record, binned:\")\n",
    "df.output_probs.apply(lambda x: len(x)).value_counts(bins=[0,1,2,3,4,5,6,50,100,500,1000,3000, df.shape[0]], sort=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rapid_healsl_chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
