{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script takes the raw responses from the OpenAI API, extracts the ICD-10 codes and their associated probabilities,\n",
    "\n",
    "Pseudo code\n",
    "-----------\n",
    "1. Load the data from file.\n",
    "2. Parse the feature \"logprobs\" and match with various ICD10 code patterns.\n",
    "    2.1 Extract only the tokens that forms the ICD10 code pattern and its associated probability.\n",
    "    2.2 Calculate the mean linear probability of all the tokens involved.\n",
    "    2.3 Save the ICD10 code, mean linear probability, and relevant information in to \"output_probs\"\n",
    "3. Sort ICD10 codes in \"output_probs\" by their mean linear probability in descending order.\n",
    "4. Extract the top 5 ICD10 codes and their associated mean linear probabilities into their own columns.\n",
    "5. Reorder the columns and save the dataframe to file.\n",
    "\n",
    "\n",
    "Details regarding #2.1 of the pseudo code:\n",
    "------------------------------------------\n",
    "\n",
    "Although we specified the requirements in the API prompts, the response output sometimes contain additional information, \n",
    "such as extra descriptions, multiple ICD10 codes, or other unrelated information. There are only few dozens of such cases\n",
    "in over ten thousand responses. Nevertheless, these need to be handled as there can only be one best ICD10 code. In \n",
    "general, we look into the output message, find all the ICD10 codes, calculate their mean probability, and save only ICD10 \n",
    "codes with the top 5 highest mean probabilities.\n",
    "\n",
    "\n",
    "Details regarding #2.1 of the pseudo code:\n",
    "------------------------------------------\n",
    "\n",
    "An output message may show only one ICD10 code, but behind the scenes, the code is formed by a number of tokens. For \n",
    "example, an output message of \"M54.2\" is composed of four tokens: \"M\", \"54\", \".\", and \"2\". Each token has its own log \n",
    "probability. All probabilities are recorded in the \"logprobs\" feature as an array. \n",
    "\n",
    "The mean probability of a single ICD10 code is simple to calculate as we can just take the mean of the whole array.\n",
    "However, when output message consists of multiple ICD10 codes or unrelated text, 'logprobs' must be parsed to extract \n",
    "only the relevant tokens.\n",
    "\n",
    "We use a sliding window of various sizes to match different ICD10 code pattern using regular expressions. The pattern is\n",
    "as follows:\n",
    "\n",
    "    - ANN.ANNN\n",
    "    - ANN.ANN\n",
    "    - ANN\n",
    "\n",
    "... where A is a letter and N is a number.\n",
    "\n",
    "This will allow us to capture from the most detailed ICD10 code (e.g. G83.9) to the broadest (e.g. B54).\n",
    "\n",
    "\n",
    "Details regarding #2.2 of the pseudo code:\n",
    "------------------------------------------\n",
    "The formula used for calculating the mean linear probability is:\n",
    "\n",
    "    Linear_Mean_Probability = (1/n) * sum(exp(logprob_i) for i in 1 to n)\n",
    "\n",
    "... where \"logprobs\" is a list of log probabilities associated with the tokens that form the ICD10 code.\n",
    "\n",
    "        \n",
    "Details regarding #5 of the pseudo code:\n",
    "----------------------------------------\n",
    "\n",
    "Below is the data structure of the parsed data:\n",
    "\n",
    "    dataframe() = []\n",
    "        'cause(n)_icd10': the unique identifier for the response. (n) can be 1 to 5.\n",
    "        'cause(n)_icd10_prob': the mean linear probability of the ICD10 code. (n) can be 1 to 5.\n",
    "        'output_timestamp': \n",
    "        'output_model': \n",
    "        'output_system_prompt': \n",
    "        'output_user_prompt':\n",
    "        'output_usage_completion_tokens': Number of tokens used by completion\n",
    "        'output_usage_prompt_tokens': Number of tokens used by prompt\n",
    "        'output_probs': Extracted ICD-10 codes, linear mean, and their associated token probabilities.        \n",
    "        'other_columns': columns carried over from the original dataframe. (optional; by setting)\n",
    "        'raw': the original raw response (optional; by setting)\n",
    "    ]\n",
    "\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/dwx9rt0d03d6hmp1hj2xtrdr0000gp/T/ipykernel_39161/1736583321.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# return the current date and time as a string\n",
    "def get_datetime_string():\n",
    "    return datetime.now().strftime('%Y%m%d_%H%M')\n",
    "\n",
    "IMPORT_DATA = \"all_data_0309.json\"           # Input response data file\n",
    "# OUTPUT_FILE filename is automatically generated\n",
    "\n",
    "PAIRS = 5           # Generate up to 5 ICDs\n",
    "\n",
    "# DROP Settings\n",
    "DROP_EXCESS_COLUMNS = False         # Drop 'other_columns' from output dataframe\n",
    "DROP_RAW = False                     # Drop 'raw' from output dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Get export filenames based on input filename\n",
    "\n",
    "def generate_export_filename(file) -> tuple[str, str]:\n",
    "    '''\n",
    "    Takes a file name as input and returns a tuple containing the names of the parsed JSON and CSV files.\n",
    "\n",
    "    Parameters:\n",
    "        file (str): The name of the input file.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str(json), str(csv)]: A tuple containing the names of the parsed JSON and CSV files.\n",
    "    '''\n",
    "    temp = file.split(\".json\")[0]\n",
    "    return f\"{temp}_parsed.json\", f\"{temp}_parsed.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Initialize the data storage dictionary\n",
    "\n",
    "def load_data(filename=IMPORT_DATA):\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{filename} found. Loading data...\")\n",
    "        with open(filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"{filename} not found. Initializing empty dictionary...\")\n",
    "        return {}\n",
    "\n",
    "def save_data(data, filename=IMPORT_DATA):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Extract ICD probabilities from tokens\n",
    "\n",
    "def extract_icd_probabilities(logprobs, debug=False):\n",
    "    \"\"\"\n",
    "    Extracts ICD-10 codes and their associated probabilities from a list of tokens and log probabilities.\n",
    "\n",
    "    This function iterates over the list of tokens and log probabilities, concatenating tokens together \n",
    "    and checking if they match the pattern of an ICD-10 code. If a match is found, it calculates the mean \n",
    "    linear probability of the ICD-10 code and packages the ICD-10 code, mean linear probability, and \n",
    "    associated tokens and log probabilities into a dictionary. It then appends this dictionary to a list \n",
    "    of parsed ICD-10 codes.\n",
    "\n",
    "    Args:\n",
    "        logprobs (list): A list of lists, where each inner list contains a token and its associated log probability.\n",
    "        debug (bool, optional): If set to True, the function prints debug information. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains an ICD-10 code, its mean linear probability, \n",
    "              and a dictionary of associated tokens and log probabilities.\n",
    "    \"\"\"\n",
    "    parsed_icds = []\n",
    "    tmp_df = pd.DataFrame(logprobs)\n",
    "    if debug > 0:\n",
    "        print(repr(''.join(tmp_df.iloc[:,0])))\n",
    "    tmp_df_limit = len(tmp_df)\n",
    "    for pos in range(tmp_df_limit):\n",
    "        # Concatenate 2, 4, or 5 tokens to form ICD-10 codes\n",
    "        temp_concat_ANN = ''.join(tmp_df.iloc[pos:pos+2, 0]).strip()\n",
    "        temp_concat_ANN_NNN = ''.join(tmp_df.iloc[pos:pos+4, 0]).strip()\n",
    "        temp_concat_ANN_NNN_A = ''.join(tmp_df.iloc[pos:pos+5, 0]).strip()\n",
    "        temp_concat_ANA_NNN = ''.join(tmp_df.iloc[pos:pos+5, 0]).strip()\n",
    "        \n",
    "        # Reference: https://www.webpt.com/blog/understanding-icd-10-code-structure\n",
    "        \n",
    "        # Regular expression pattern for various ICD-10 codes in the format\n",
    "        # 'ANN' (e.g., 'A10')\n",
    "        # 'ANN.NNN' (e.g., 'A10.001')\n",
    "        # 'ANN.NNNA' (e.g., 'A10.001A') \n",
    "        # Note: last alphabet valid only if there are 6 characters before it\n",
    "        # pattern_ANN = r\"^[A-Z]\\d{2}$\"\n",
    "        pattern_ANN = r\"^[A-Z]\\d[0-9A-Z]$\"\n",
    "        # pattern_ANN_NNN = r\"^[A-Z]\\d{2}\\.\\d{1,3}$\"        \n",
    "        pattern_ANN_NNN = r\"^[A-Z]\\d[0-9A-Z]\\.\\d{1,3}$\"        \n",
    "        # pattern_ANN_NNN_A = r\"^[A-Z]\\d{2}\\.\\d{3}[A-Z]$\"\n",
    "        pattern_ANN_NNN_A = r\"^[A-Z]\\d[0-9A-Z]\\.\\d{3}[A-Z]$\"        \n",
    "        \n",
    "        # Check if the concatenated tokens match the ICD-10 code patterns\n",
    "        match_ANN = re.match(pattern_ANN, temp_concat_ANN)\n",
    "        match_ANN_NNN = re.match(pattern_ANN_NNN, temp_concat_ANN_NNN)\n",
    "        match_ANN_NNN_A = re.match(pattern_ANN_NNN_A, temp_concat_ANN_NNN_A)\n",
    "        match_ANA_NNN = re.match(pattern_ANN_NNN, temp_concat_ANA_NNN)\n",
    "        \n",
    "        # [debug] Each line will show which of the 3 patterns matched for the 3 token\n",
    "        if debug == 2:\n",
    "            print(\n",
    "                str(pos).ljust(4), \n",
    "                repr(temp_concat_ANN).ljust(10), \n",
    "                ('yes' if match_ANN else 'no').ljust(15), \n",
    "                repr(temp_concat_ANN_NNN).ljust(10), \n",
    "                ('yes' if match_ANN_NNN else 'no').ljust(15), \n",
    "                repr(temp_concat_ANN_NNN_A).ljust(10), \n",
    "                ('yes' if match_ANN_NNN_A else 'no').ljust(15),\n",
    "                repr(temp_concat_ANA_NNN).ljust(10), \n",
    "                ('yes' if match_ANA_NNN else 'no').ljust(5)\n",
    "                )\n",
    "        \n",
    "        # Check match from longest to shortest\n",
    "        # If a match is found, calculate the mean linear probability \n",
    "        # and package the ICD-10 code and associated data\n",
    "        if match_ANN_NNN_A:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+5])\n",
    "            winning_icd = temp_concat_ANN_NNN_A\n",
    "        elif match_ANA_NNN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+5])\n",
    "            winning_icd = temp_concat_ANA_NNN\n",
    "        elif match_ANN_NNN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+4])\n",
    "            winning_icd = temp_concat_ANN_NNN            \n",
    "        elif match_ANN:\n",
    "            winning_df = pd.DataFrame(logprobs[pos:pos+2])\n",
    "            winning_icd = temp_concat_ANN            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # [debug] Display the winning ICD-10 code and its associated data\n",
    "        if debug == 2:\n",
    "            print(f\"**** {winning_icd} - VALID ICD ****\")\n",
    "            display(winning_df)\n",
    "        \n",
    "        # Convert log probabilities to linear probabilities and calculate the mean\n",
    "        winning_mean = np.exp(winning_df.iloc[:, 1]).mean()\n",
    "        \n",
    "        # Package the ICD-10 code and associated data\n",
    "        winning_package = {\n",
    "            'icd': winning_icd,\n",
    "            'icd_linprob_mean': winning_mean,\n",
    "            'logprobs': winning_df.rename(columns={0: 'token', 1:'logprob'}).to_dict(orient='list')\n",
    "        }\n",
    "        \n",
    "        # Append the package to the list of parsed ICD-10 codes\n",
    "        parsed_icds.append(winning_package)\n",
    "    \n",
    "    # [debug] Display the parsed ICD-10 codes\n",
    "    if debug > 0:\n",
    "        display(parsed_icds) \n",
    "    \n",
    "    # Check if parsed_icds is empty\n",
    "    if not parsed_icds:\n",
    "        # If it is, raise an error and show the logprobs in question\n",
    "        raise ValueError(f\"No ICD-10 codes could be parsed from the provided logprobs: {logprobs}\")\n",
    "\n",
    "    return parsed_icds\n",
    "\n",
    "# # Uncomment the following lines to test the function. \n",
    "# # `test` is an example of the `logprobs` field from the JSON data.\n",
    "# test = [['A', -0.63648945],  ['09', -1.4643841], ['\\n', -0.9866263], ['R', -0.6599979], ['50', -1.5362289],\n",
    "#  ['.', -0.05481864],  ['9', -0.002321772], ['\\n', -0.3524723], ['R', -0.56709456], ['11', -1.263591],\n",
    "#  ['.', -0.05834798], ['0', -0.73551023], ['\\n', -0.5051807], ['R', -0.65759194], ['63', -1.0282977],\n",
    "#  ['.', -0.0006772888], ['4', -0.71002203]]\n",
    "\n",
    "# test_output = extract_icd_probabilities(test)\n",
    "# test_output\n",
    "\n",
    "# # Uncomment to test a specific case\n",
    "# extract_icd_probabilities(df.loc['24000015', 'logprobs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./all_data_0309.json found. Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data and convert to dataframe\n",
    "data_storage = load_data()\n",
    "df = pd.DataFrame(data_storage).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_EXPORT_FILE, CSV_EXPORT_FILE = generate_export_filename(IMPORT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unrecognized colnames\n",
    "required_colnames = ['uid', 'rowid', 'param_model', 'param_temperature',\n",
    "                     'param_logprobs', 'param_system_prompt', 'param_user_prompt',\n",
    "                     'timestamp', 'output']\n",
    "\n",
    "# Get columns names that are not required\n",
    "extra_colnames = [colname for colname in df.columns if colname not in required_colnames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    output_msg = df.output.apply(lambda x: x['choices'][0]['message']['content']),\n",
    "    output_logprobs = df.output.apply(lambda x: [(token['token'], float(token['logprob'])) for token in x['choices'][0]['logprobs']['content']]),\n",
    "    output_usage_completion_tokens = df.output.apply(lambda x: x['usage']['completion_tokens']),\n",
    "    output_usage_prompt_tokens = df.output.apply(lambda x: x['usage']['prompt_tokens'])\n",
    "    \n",
    ")\n",
    "\n",
    "# Extract ICD-10 codes and their associated probabilities as a new column\n",
    "df = df.assign(output_probs=df['output_logprobs'].apply(extract_icd_probabilities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x): Given a list of ICDs in form of a list of tuples, convert each ICD into 1-dimension Series\n",
    "\n",
    "def output_icds_to_cols(value, pairs=PAIRS):\n",
    "    \"\"\"\n",
    "    Converts a list of ICD-10 codes and their associated probabilities into a one-dimensional pandas Series.\n",
    "\n",
    "    This function takes a list of tuples, where each tuple contains an ICD-10 code and its associated \n",
    "    probability. It converts this list into a DataFrame, sorts the DataFrame by descending probability, \n",
    "    drops the 'logprobs' column, reshapes the DataFrame into a one-dimensional Series, and pads the Series \n",
    "    to fill a specified number of columns.\n",
    "\n",
    "    Args:\n",
    "        value (list): A list of tuples, where each tuple contains an ICD-10 code and its associated probability.\n",
    "        pairs (int, optional): The number of columns to pad the Series to. Defaults to PAIRS.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: A one-dimensional Series containing the ICD-10 codes and their associated probabilities.\n",
    "    \"\"\"\n",
    "    tmp = pd.DataFrame(value) # convert list of tuples to dataframe\n",
    "    tmp = tmp.sort_values(by=\"icd_linprob_mean\", ascending=False) # sort by descending probability\n",
    "    tmp = tmp.drop(columns=['logprobs'])\n",
    "    tmp = tmp.stack().reset_index(drop=True) # convert to 1 row\n",
    "    tmp = tmp.reindex(range(pairs*2), axis=1) # pad to fill PAIRS*2 columns\n",
    "    return tmp\n",
    "\n",
    "# Test\n",
    "# output_icds_to_cols(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate column names for the exploded ICDs in cause{n}_icd10 and cause{n}_icd10_prob format\n",
    "icd_column_names_mapping = {i: f\"cause{i // 2 + 1}_icd10\" if i % 2 == 0 else f\"cause{i // 2 + 1}_icd10_prob\" for i in range(PAIRS*2)}\n",
    "\n",
    "# Apply the `output_icds_to_cols` function to the `output_probs` column\n",
    "# This will explode the ICDs into separate columns\n",
    "parsed_df = df.merge(df.output_probs.apply(output_icds_to_cols).rename(columns=icd_column_names_mapping), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Takes usage and extracts the first 2 values into separate columns\n",
    "# parsed_df = parsed_df.merge(\n",
    "#     parsed_df['usage'].apply(lambda x: pd.DataFrame(x).iloc[:2,1])\n",
    "#     .rename(columns={\n",
    "#         0: \"output_usage_completion_tokens\",\n",
    "#         1: \"output_usage_prompt_tokens\"\n",
    "#         }), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'rowid', 'param_model', 'param_temperature', 'param_logprobs',\n",
       "       'param_system_prompt', 'param_user_prompt', 'timestamp', 'output',\n",
       "       'age_group', 'round', 'output_msg', 'output_logprobs',\n",
       "       'output_usage_completion_tokens', 'output_usage_prompt_tokens',\n",
       "       'output_probs', 'cause1_icd10', 'cause1_icd10_prob', 'cause2_icd10',\n",
       "       'cause2_icd10_prob', 'cause3_icd10', 'cause3_icd10_prob',\n",
       "       'cause4_icd10', 'cause4_icd10_prob', 'cause5_icd10',\n",
       "       'cause5_icd10_prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping variable\n",
    "column_mapping = {\n",
    "    'model': 'output_model',\n",
    "    'system_prompt': 'output_system_prompt',\n",
    "    'user_prompt': 'output_user_prompt',\n",
    "    'user_prompt': 'output_user_prompt',\n",
    "    'timestamp': 'output_created',\n",
    "}\n",
    "\n",
    "# Rename the columns using the mapping\n",
    "parsed_df = parsed_df.rename(columns=column_mapping)\n",
    "\n",
    "export_columns = []\n",
    "export_columns += ['rowid']\n",
    "export_columns += list(icd_column_names_mapping.values())\n",
    "export_columns += [\n",
    "                    'output_created',\n",
    "                    'param_model',\n",
    "                    'param_system_prompt' , \n",
    "                    'param_user_prompt', \n",
    "                    'output_usage_completion_tokens', \n",
    "                    'output_usage_prompt_tokens', \n",
    "                    'output_msg',\n",
    "                    'output_probs'\n",
    "                ]\n",
    "\n",
    "if not DROP_EXCESS_COLUMNS:\n",
    "    export_columns += extra_colnames\n",
    "    \n",
    "if not DROP_RAW:\n",
    "    export_columns += ['output']\n",
    "\n",
    "\n",
    "# Show only relevant columns in the final dataframe\n",
    "export_parsed_df = parsed_df[export_columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'id': 'chatcmpl-90mt9wsYAOwOYM9OV18cKC9v4N3mk', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': {'content': [{'token': 'I', 'bytes': [73], 'logprob': -0.13396642, 'top_logprobs': []}, {'token': '10', 'bytes': [49, 48], 'logprob': -1.1009063, 'top_logprobs': []}]}, 'message': {'content': 'I10', 'role': 'assistant', 'function_call': None, 'tool_calls': None}}], 'created': 1709974955, 'model': 'gpt-3.5-turbo-0125', 'object': 'chat.completion', 'system_fingerprint': 'fp_2b778c6b35', 'usage': {'completion_tokens': 2, 'prompt_tokens': 375, 'total_tokens': 377}}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_parsed_df.head(1).output.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export Dataframe shape: (11887, 22)\n",
      "Processed file exporting to: _parsed.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Export Dataframe shape: {export_parsed_df.shape}\")\n",
    "print(f\"Processed file exporting to: {CSV_EXPORT_FILE}\")\n",
    "\n",
    "# Save the parsed data to a JSON file\n",
    "# export_parsed_df.to_json(JSON_EXPORT_FILE, orient='records')\n",
    "export_parsed_df.to_csv(CSV_EXPORT_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rapid_healsl_chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
