{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import textwrap\n",
    "import datetime\n",
    "import pytz\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPORTION_SAMPLING = True\n",
    "N_REPEAT_RESPONSES = 10\n",
    "N_SAMPLES = 100  # Replace X with the desired number of values to select\n",
    "OUTPUT_FILE = \"output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyl\\AppData\\Local\\Temp\\ipykernel_38160\\97552092.py:10: DtypeWarning: Columns (2,105,205,206,215,216,316) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n",
      "C:\\Users\\andyl\\AppData\\Local\\Temp\\ipykernel_38160\\97552092.py:10: DtypeWarning: Columns (182,245) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: rd1        age group: adult      len: 4987      \n",
      "round: rd1        age group: child      len: 2998      \n",
      "round: rd1        age group: neo        len: 585       \n",
      "round: rd2        age group: adult      len: 2025      \n",
      "round: rd2        age group: child      len: 1059      \n",
      "round: rd2        age group: neo        len: 233       \n",
      "\n",
      "Total length of merged_all_df: 11887\n"
     ]
    }
   ],
   "source": [
    "path_prefix = \"../data_202402/\"\n",
    "merged_all_df = pd.DataFrame()\n",
    "\n",
    "rounds = ['rd1', 'rd2']\n",
    "age_groups = ['adult', 'child', 'neo']\n",
    "\n",
    "for r in rounds:\n",
    "    for a in age_groups:\n",
    "        \n",
    "        questionnaire_df =  pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_v1.csv\")\n",
    "        age_df =            pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_age_v1.csv\")\n",
    "        narrative_df =      pd.read_csv(f\"{path_prefix}healsl_{r}_{a}_narrative_v1.csv\")\n",
    "\n",
    "        narrative_df = narrative_df.rename(columns={'summary': 'open_narrative'})\n",
    "        \n",
    "        # Merge the dataframes\n",
    "        narrative_only = narrative_df[['rowid','open_narrative']]\n",
    "        sex_only = questionnaire_df[['rowid','sex_cod']]\n",
    "        age_only = age_df[['rowid','age_value_death','age_unit_death']]\n",
    "        \n",
    "        merged_df = narrative_only.merge(sex_only, on='rowid').merge(age_only, on='rowid')\n",
    "\n",
    "        # Fill in missing values with empty string\n",
    "        merged_df['sex_cod'] = merged_df['sex_cod'].fillna('')\n",
    "        \n",
    "        merged_df['group'] = f\"{a}_{r}\"\n",
    "\n",
    "        assert not merged_df.isnull().values.any(), \"Execution halted: NaN values found in merged_df\"\n",
    "\n",
    "        print(f\"round: {r.ljust(10)} age group: {a.ljust(10)} len: {str(merged_df.shape[0]).ljust(10)}\")\n",
    "        # print(f\"Sample of merged_df {merged_df.shape}:\")\n",
    "        # display(merged_df.sample(5))\n",
    "        \n",
    "        merged_all_df = pd.concat([merged_all_df, merged_df])\n",
    "\n",
    "print(\"\")        \n",
    "print(f\"Total length of merged_all_df: {len(merged_all_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult_rd1: 42 records\n",
      "child_rd1: 25 records\n",
      "adult_rd2: 17 records\n",
      "child_rd2: 9 records\n",
      "neo_rd1: 5 records\n",
      "neo_rd2: 2 records\n",
      "There are 100 samples. No need to remove any samples.\n"
     ]
    }
   ],
   "source": [
    "# Taking a sample of the merged_all_df\n",
    "if PROPORTION_SAMPLING:    \n",
    "\n",
    "    # Get the sampling fraction\n",
    "    sampling_frac = ((merged_all_df.value_counts('group') / len(merged_all_df)) * N_SAMPLES).round(0).astype(int).to_dict()\n",
    "    \n",
    "    # Initialize the dictionary to store the sample ids\n",
    "    sample_ids = {}\n",
    "\n",
    "    # Get sample based on fraction for each group\n",
    "    for sample in sampling_frac:\n",
    "        sample_ids[sample] = merged_all_df[merged_all_df['group'] == sample].sample(sampling_frac[sample], random_state=1).rowid.tolist()    \n",
    "        print(f\"{sample}: {sampling_frac[sample]} records\")\n",
    "        \n",
    "    # Sort dict from largest group to smallest\n",
    "    sorted_sample_ids = dict(sorted(sample_ids.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "\n",
    "    # Get the actual samples count\n",
    "    sample_values_count = len([item for subitem in sorted_sample_ids.values() for item in subitem])\n",
    "\n",
    "    # If sample count is more than N_SAMPLES required, remove the excess samples\n",
    "    # starting from the group with the most samples and more than 10 samples\n",
    "    if sample_values_count > N_SAMPLES: \n",
    "        excess = sample_values_count - N_SAMPLES\n",
    "        print(f\"There are more than {N_SAMPLES} samples. Removing excess samples.\")\n",
    "                \n",
    "        for _ in range(excess):\n",
    "            for key in sorted_sample_ids:\n",
    "                \n",
    "                if len(sorted_sample_ids[key]) > 10:\n",
    "                    sorted_sample_ids[key].pop()\n",
    "                    break\n",
    "    else:\n",
    "        print(f\"There are {sample_values_count} samples. No need to remove any samples.\")\n",
    "        \n",
    "    # Flatten the sample dictionary to a list of rowids\n",
    "    sample_ids_list = [item for sublist in sorted_sample_ids.values() for item in sublist]\n",
    "\n",
    "    # Compile a dataframe based on the sample rowids\n",
    "    random_rowids = merged_all_df[merged_all_df['rowid'].isin(sample_ids_list)]\n",
    "    \n",
    "    # Construct a unique id rowid_repetition and append to the dataframe\n",
    "    final_df = pd.concat([random_rowids.assign(u_id=random_rowids['rowid'].astype(str) + \"_\" + str(r)) for r in range(10)])\n",
    "\n",
    "    \n",
    "# Using full dataset\n",
    "else:\n",
    "    \n",
    "    # Duplicate rowid as u_id \n",
    "    final_df = merged_all_df.assign(u_id=merged_all_df['rowid'])\n",
    "\n",
    "# Reorder u_id as first column for presentation\n",
    "final_df = final_df[['u_id'] + [col for col in final_df.columns if col != 'u_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling: True\n",
      "Shape of final dataframe: (1000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>rowid</th>\n",
       "      <th>open_narrative</th>\n",
       "      <th>sex_cod</th>\n",
       "      <th>age_value_death</th>\n",
       "      <th>age_unit_death</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>24001012_3</td>\n",
       "      <td>24001012</td>\n",
       "      <td>As per respondent the deceased was a 33 years ...</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>Years</td>\n",
       "      <td>adult_rd2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            u_id     rowid                                     open_narrative  \\\n",
       "1705  24001012_3  24001012  As per respondent the deceased was a 33 years ...   \n",
       "\n",
       "     sex_cod  age_value_death age_unit_death      group  \n",
       "1705    Male               33          Years  adult_rd2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Sampling: {PROPORTION_SAMPLING}\")\n",
    "print(f\"Shape of final dataframe: {final_df.shape}\")\n",
    "final_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check if the output file already exists. If yes, use a different name.\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        import pytz\n",
    "        import datetime\n",
    "        TIMEZONE = pytz.timezone('US/Eastern')\n",
    "\n",
    "        current_time = datetime.datetime.now(TIMEZONE)\n",
    "        formatted_time = current_time.strftime(\"%y%m%d_%H%M%S\")\n",
    "               \n",
    "        temp_output_file = OUTPUT_FILE.replace(\".csv\", f\"_{formatted_time}.csv\")\n",
    "        \n",
    "        print(f\"{OUTPUT_FILE} already exists. Saving to {temp_output_file} instead.\")\n",
    "        final_df.to_csv(temp_output_file, index=False)\n",
    "        \n",
    "    # Save dataframe as designated output file\n",
    "    else:\n",
    "        final_df.to_csv(OUTPUT_FILE, index=False)\n",
    "        \n",
    "        print(f\"Output saved to {OUTPUT_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to {OUTPUT_FILE}. Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rapid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
